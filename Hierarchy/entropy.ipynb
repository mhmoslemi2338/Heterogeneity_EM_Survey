{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.99 0.0\n",
      "27.74 0.39\n",
      "27.66 0.43\n",
      "27.16 0.46\n",
      "26.34 0.47\n",
      "25.19 0.48\n",
      "22.38 0.47\n",
      "18.5 0.42\n",
      "Fodor\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "city_hierarchy = {\n",
    "    \"united states\": {\n",
    "        \"california\": {\n",
    "            \"los angeles area\": [\n",
    "                \"los angeles (la)\", \"west la\", \"hollywood\", \"w. hollywood\", 'los angeles','la',\n",
    "                \"century\", \"chinatown\", \"studio\", \"westwood\", \"venice\", \n",
    "                \"los feliz\", \"encino\", \"sherman oaks\", \"santa monica\", \n",
    "                \"malibu\", \"beverly hills\", \"bel air\", \"manhattan beach\", \n",
    "                \"rancho park\"\n",
    "            ],\n",
    "            \"san francisco area\": [\"san francisco\"],\n",
    "            \"other california\": [\"pasadena\"]\n",
    "        },\n",
    "        \"new york\": {\n",
    "            \"new york city (nyc)\": [\"manhattan (new york)\", \"brooklyn\", \"queens\"],\n",
    "            \"other new york\": [\"marietta\"]\n",
    "        },\n",
    "        \"georgia\": {\n",
    "            \"atlanta\": [\"roswell\"]\n",
    "        },\n",
    "        \"nevada\": {\n",
    "            \"las vegas\": []\n",
    "        },\n",
    "        \"other locations\": [\"st. hermosa beach\",'lys velas']\n",
    "    }\n",
    "}\n",
    "\n",
    "restaurant_hierarchy = {\n",
    "    \"american\": {\n",
    "        \"styles\": [\"american (new)\", \"american (traditional)\", \"dive american\",'american ( new )'],\n",
    "        \"barbecue\": [\"bbq\"],\n",
    "        \"southern\": [\"cajun\", \"southern\", \"southern/soul\", \"southwestern\"],\n",
    "        \"fast food & casual\": [\n",
    "            \"hamburgers\", \"hot dogs\", \"fast food\", \"steak houses\", 'chicken',\n",
    "            \"steakhouses\", \"health food\", \"vegetarian\", \"sandwiches\",'delicatessen','delis'\n",
    "        ],\n",
    "        \"coffee\": [\"coffee bar\", \"coffee shops\", \"coffee shops/diners\", \"coffeehouses\"],\n",
    "        \"dining\": [\"diners\", \"cafeterias\", \"buffets\"]\n",
    "    },\n",
    "    \"asian\": [\"chinese\", \"japanese\", \"thai\", \"vietnamese\", \"indian\", \"indonesian\"],\n",
    "    \"european\": {\n",
    "        \"french\": [\"french\", \"french (classic)\", \"french (new)\", \"french bistro\",'french ( new )','french ( classic )'],\n",
    "        \"others\": [\n",
    "            \"greek\", \"greek and middle eastern\", \"italian\", \n",
    "            \"nuova cucina italian\", \"east european\", \n",
    "            \"polish\", \"russian\", \"scandinavian\",'continental'\n",
    "        ]\n",
    "    },\n",
    "    \"latin american & caribbean\": [\n",
    "        \"mexican\", \"tex-mex\", \"latin american\", \"mexican/latin american/spanish\",\n",
    "        \"caribbean\", \"cuban\", \"tel caribbean\"\n",
    "    ],\n",
    "    \"mediterranean\": [\"mediterranean\", \"greek\", \"greek and middle eastern\"],\n",
    "    \"seafood\": [\"seafood\"],\n",
    "    \"eclectic/international\": [\n",
    "        \"eclectic\", \"international\", \"pacific new wave\", \n",
    "        \"pacific rim\", \"californian\", \"old san francisco\", \n",
    "        \"only in las vegas\", \"ext 6108 international\", \n",
    "        \"or 212/632-5100 american\"\n",
    "    ],\n",
    "    \"desserts & specialty\": [\"desserts\", \"coffeehouses\"],\n",
    "    \"pizza\": [\"pizza\"]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# col = 'type'\n",
    "# data = list(np.unique(list(np.unique(list(pd.read_csv(f'data/{task}/tableA.csv')[col])))+list(np.unique(list(pd.read_csv(f'data/{task}/tableB.csv')[col])))))\n",
    "\n",
    "\n",
    "\n",
    "def make_mask(df,frac):\n",
    "    L = len(COL)*len(df)\n",
    "    L_disturb = int(np.ceil(L*frac))\n",
    "    disturb_mask = np.zeros((len(df),len(COL)))\n",
    "    total_elements = disturb_mask.size\n",
    "    random_indices = np.random.choice(total_elements, L_disturb, replace=False)\n",
    "    disturb_mask.flat[random_indices] = 1\n",
    "    return disturb_mask \n",
    "\n",
    "\n",
    "def find_parents(hierarchy, target, parents=None):\n",
    "    if parents is None:\n",
    "        parents = []\n",
    "\n",
    "    for key, value in hierarchy.items():\n",
    "        if key == target:  # If the target itself is a key\n",
    "            return parents + [key]\n",
    "        if isinstance(value, dict):  # If value is a nested dictionary\n",
    "            result = find_parents(value, target, parents + [key])\n",
    "            if result != -1:\n",
    "                return result\n",
    "        elif isinstance(value, list) and target in value:  # If value is a list containing the target\n",
    "            return parents + [key]\n",
    "\n",
    "    return -1  # Return -1 if the target is not found\n",
    "\n",
    "\n",
    "def disturb_func(col,value):\n",
    "    if col =='city':\n",
    "        \n",
    "        parents = find_parents(city_hierarchy, value.lower())\n",
    "        if parents == -1: print(value)\n",
    "\n",
    "        np.random.shuffle(parents)\n",
    "        new_velue = parents[0]\n",
    "        \n",
    "\n",
    "    elif col == 'typee':\n",
    "        parents = find_parents(restaurant_hierarchy, value.lower())\n",
    "        if parents == -1: print(value)\n",
    "        np.random.shuffle(parents)\n",
    "        new_velue = parents[0]\n",
    "\n",
    "    elif col =='class':\n",
    "        data = [int(value)]\n",
    "        number_hierarchy = {\n",
    "            \"0-99\": [n for n in data if 0 <= n <= 99],\n",
    "            \"100-199\": [n for n in data if 100 <= n <= 199],\n",
    "            \"200-299\": [n for n in data if 200 <= n <= 299],\n",
    "            \"300-399\": [n for n in data if 300 <= n <= 399],\n",
    "            \"400-499\": [n for n in data if 400 <= n <= 499],\n",
    "            \"500-599\": [n for n in data if 500 <= n <= 599],\n",
    "            \"600-699\": [n for n in data if 600 <= n <= 699],\n",
    "            \"700-799\": [n for n in data if 700 <= n <= 799]\n",
    "        }\n",
    "        new_velue = next((key for key, values in number_hierarchy.items() if values), None)\n",
    "\n",
    "    return new_velue\n",
    "task = 'Fodors-Zagat'\n",
    "COL = ['class','typee','city']\n",
    "\n",
    "def column_entropy(column):\n",
    "    column = column.fillna('nan')\n",
    "    value_counts = column.value_counts()\n",
    "    probabilities = value_counts / len(column)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "for frac in [0, 0.1,0.2,0.3,0.4,0.5,0.7,0.9]:\n",
    "    L =[]\n",
    "    R = []\n",
    "\n",
    "    for rep in range(1,101):\n",
    "        df = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/data/\" + task  +'/test.csv')\n",
    "\n",
    "\n",
    "        mask_left = make_mask(df,frac)\n",
    "        mask_right = make_mask(df,frac)\n",
    "\n",
    "\n",
    "        df['left_class'] = df['left_class'].astype(str)\n",
    "        df['right_class'] = df['right_class'].astype(str)\n",
    "        x = 0\n",
    "        for i,col in enumerate(COL):\n",
    "            \n",
    "            df.loc[mask_left[:,i] == 1, 'left_'+col] = df.loc[mask_left[:,i] == 1, 'left_'+col].apply(lambda x: disturb_func(col, x))\n",
    "            df.loc[mask_right[:,i] == 1, 'right_'+col] = df.loc[mask_right[:,i] == 1, 'right_'+col].apply(lambda x: disturb_func(col, x))\n",
    "\n",
    "            x+=(column_entropy(df['left_'+col]) +column_entropy(df['right_'+col]))\n",
    "\n",
    "        L.append(x)\n",
    "    if frac ==0:\n",
    "        base = np.average(L).copy()\n",
    "    base =1\n",
    "    print(round(np.average(L)/base,2), round(np.sqrt(np.std(L))/base,2))\n",
    "\n",
    "print('Fodor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.99 0.0\n",
      "27.77 0.38\n",
      "27.66 0.44\n",
      "27.14 0.48\n",
      "26.3 0.48\n",
      "25.25 0.5\n",
      "Fodor\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "city_hierarchy = {\n",
    "    \"united states\": {\n",
    "        \"california\": {\n",
    "            \"los angeles area\": [\n",
    "                \"los angeles (la)\", \"west la\", \"hollywood\", \"w. hollywood\", 'los angeles','la',\n",
    "                \"century\", \"chinatown\", \"studio\", \"westwood\", \"venice\", \n",
    "                \"los feliz\", \"encino\", \"sherman oaks\", \"santa monica\", \n",
    "                \"malibu\", \"beverly hills\", \"bel air\", \"manhattan beach\", \n",
    "                \"rancho park\"\n",
    "            ],\n",
    "            \"san francisco area\": [\"san francisco\"],\n",
    "            \"other california\": [\"pasadena\"]\n",
    "        },\n",
    "        \"new york\": {\n",
    "            \"new york city (nyc)\": [\"manhattan (new york)\", \"brooklyn\", \"queens\"],\n",
    "            \"other new york\": [\"marietta\"]\n",
    "        },\n",
    "        \"georgia\": {\n",
    "            \"atlanta\": [\"roswell\"]\n",
    "        },\n",
    "        \"nevada\": {\n",
    "            \"las vegas\": []\n",
    "        },\n",
    "        \"other locations\": [\"st. hermosa beach\",'lys velas']\n",
    "    }\n",
    "}\n",
    "\n",
    "restaurant_hierarchy = {\n",
    "    \"american\": {\n",
    "        \"styles\": [\"american (new)\", \"american (traditional)\", \"dive american\",'american ( new )'],\n",
    "        \"barbecue\": [\"bbq\"],\n",
    "        \"southern\": [\"cajun\", \"southern\", \"southern/soul\", \"southwestern\"],\n",
    "        \"fast food & casual\": [\n",
    "            \"hamburgers\", \"hot dogs\", \"fast food\", \"steak houses\", 'chicken',\n",
    "            \"steakhouses\", \"health food\", \"vegetarian\", \"sandwiches\",'delicatessen','delis'\n",
    "        ],\n",
    "        \"coffee\": [\"coffee bar\", \"coffee shops\", \"coffee shops/diners\", \"coffeehouses\"],\n",
    "        \"dining\": [\"diners\", \"cafeterias\", \"buffets\"]\n",
    "    },\n",
    "    \"asian\": [\"chinese\", \"japanese\", \"thai\", \"vietnamese\", \"indian\", \"indonesian\"],\n",
    "    \"european\": {\n",
    "        \"french\": [\"french\", \"french (classic)\", \"french (new)\", \"french bistro\",'french ( new )','french ( classic )'],\n",
    "        \"others\": [\n",
    "            \"greek\", \"greek and middle eastern\", \"italian\", \n",
    "            \"nuova cucina italian\", \"east european\", \n",
    "            \"polish\", \"russian\", \"scandinavian\",'continental'\n",
    "        ]\n",
    "    },\n",
    "    \"latin american & caribbean\": [\n",
    "        \"mexican\", \"tex-mex\", \"latin american\", \"mexican/latin american/spanish\",\n",
    "        \"caribbean\", \"cuban\", \"tel caribbean\"\n",
    "    ],\n",
    "    \"mediterranean\": [\"mediterranean\", \"greek\", \"greek and middle eastern\"],\n",
    "    \"seafood\": [\"seafood\"],\n",
    "    \"eclectic/international\": [\n",
    "        \"eclectic\", \"international\", \"pacific new wave\", \n",
    "        \"pacific rim\", \"californian\", \"old san francisco\", \n",
    "        \"only in las vegas\", \"ext 6108 international\", \n",
    "        \"or 212/632-5100 american\"\n",
    "    ],\n",
    "    \"desserts & specialty\": [\"desserts\", \"coffeehouses\"],\n",
    "    \"pizza\": [\"pizza\"]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# col = 'type'\n",
    "# data = list(np.unique(list(np.unique(list(pd.read_csv(f'data/{task}/tableA.csv')[col])))+list(np.unique(list(pd.read_csv(f'data/{task}/tableB.csv')[col])))))\n",
    "\n",
    "\n",
    "\n",
    "def make_mask(df,frac):\n",
    "    L = len(COL)*len(df)\n",
    "    L_disturb = int(np.ceil(L*frac))\n",
    "    disturb_mask = np.zeros((len(df),len(COL)))\n",
    "    total_elements = disturb_mask.size\n",
    "    random_indices = np.random.choice(total_elements, L_disturb, replace=False)\n",
    "    disturb_mask.flat[random_indices] = 1\n",
    "    return disturb_mask \n",
    "\n",
    "\n",
    "def find_parents(hierarchy, target, parents=None):\n",
    "    if parents is None:\n",
    "        parents = []\n",
    "\n",
    "    for key, value in hierarchy.items():\n",
    "        if key == target:  # If the target itself is a key\n",
    "            return parents + [key]\n",
    "        if isinstance(value, dict):  # If value is a nested dictionary\n",
    "            result = find_parents(value, target, parents + [key])\n",
    "            if result != -1:\n",
    "                return result\n",
    "        elif isinstance(value, list) and target in value:  # If value is a list containing the target\n",
    "            return parents + [key]\n",
    "\n",
    "    return -1  # Return -1 if the target is not found\n",
    "\n",
    "\n",
    "def disturb_func(col,value):\n",
    "    if col =='city':\n",
    "        \n",
    "        parents = find_parents(city_hierarchy, value.lower())\n",
    "        if parents == -1: print(value)\n",
    "\n",
    "        np.random.shuffle(parents)\n",
    "        new_velue = parents[0]\n",
    "        \n",
    "\n",
    "    elif col == 'typee':\n",
    "        parents = find_parents(restaurant_hierarchy, value.lower())\n",
    "        if parents == -1: print(value)\n",
    "        np.random.shuffle(parents)\n",
    "        new_velue = parents[0]\n",
    "\n",
    "    elif col =='class':\n",
    "        data = [int(value)]\n",
    "        number_hierarchy = {\n",
    "            \"0-99\": [n for n in data if 0 <= n <= 99],\n",
    "            \"100-199\": [n for n in data if 100 <= n <= 199],\n",
    "            \"200-299\": [n for n in data if 200 <= n <= 299],\n",
    "            \"300-399\": [n for n in data if 300 <= n <= 399],\n",
    "            \"400-499\": [n for n in data if 400 <= n <= 499],\n",
    "            \"500-599\": [n for n in data if 500 <= n <= 599],\n",
    "            \"600-699\": [n for n in data if 600 <= n <= 699],\n",
    "            \"700-799\": [n for n in data if 700 <= n <= 799]\n",
    "        }\n",
    "        new_velue = next((key for key, values in number_hierarchy.items() if values), None)\n",
    "\n",
    "    return new_velue\n",
    "task = 'Fodors-Zagat'\n",
    "COL = ['class','typee','city']\n",
    "\n",
    "def column_entropy(column):\n",
    "    column = column.fillna('nan')\n",
    "    value_counts = column.value_counts()\n",
    "    probabilities = value_counts / len(column)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "for frac in [0, 0.1,0.2,0.3,0.4,0.5]:\n",
    "    L =[]\n",
    "    R = []\n",
    "\n",
    "    for rep in range(1,101):\n",
    "        df = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/data/\" + task  +'/test.csv')\n",
    "\n",
    "\n",
    "        mask_left = make_mask(df,frac)\n",
    "        mask_right = make_mask(df,frac)\n",
    "\n",
    "\n",
    "        df['left_class'] = df['left_class'].astype(str)\n",
    "        df['right_class'] = df['right_class'].astype(str)\n",
    "        x = 0\n",
    "        for i,col in enumerate(COL):\n",
    "            \n",
    "            df.loc[mask_left[:,i] == 1, 'left_'+col] = df.loc[mask_left[:,i] == 1, 'left_'+col].apply(lambda x: disturb_func(col, x))\n",
    "            df.loc[mask_right[:,i] == 1, 'right_'+col] = df.loc[mask_right[:,i] == 1, 'right_'+col].apply(lambda x: disturb_func(col, x))\n",
    "\n",
    "            x+=(column_entropy(df['left_'+col]) +column_entropy(df['right_'+col]))\n",
    "\n",
    "        L.append(x)\n",
    "    if frac ==0:\n",
    "        base = np.average(L).copy()\n",
    "    base =1\n",
    "    print(round(np.average(L)/base,2), round(np.sqrt(np.std(L))/base,2))\n",
    "\n",
    "print('Fodor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.17 0.0\n",
      "39.18 0.46\n",
      "38.04 0.82\n",
      "36.15 0.7\n",
      "35.01 0.73\n",
      "32.66 1.05\n",
      "walamrt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "brand_hierarchy = {\n",
    "    \"Electronics\": {\n",
    "        \"Computers\": [\"acer\", \"alienware\", \"apple\", \"asus\", \"dell\", \"lenovo\", \"microsoft\", \"a-data\", \"a4tech\", \"accell\", \"avid\", \"azio\", \"ibm\", \"4inkjets\", \"acme\", \"acme made\", \"acp\", \"acp-ep memory\", \"agama\", \"aoc\", \"apc\", \"arclyte technologies inc.\", \"atlona\", \"atrend\", \"aurora\", \"avf\", \"basyx\", \"bell o\", \"bling software\", \"blurex\", \"bracketron\", \"buffalo technology\", \"built ny\"],\n",
    "        \"Components\": [\"3m\", \"corsair\", \"kingston\", \"seagate\", \"sandisk\", \"western digital\", \"dane\", \"dane-elec\", \"diamond multimedia\", \"bits limited\", \"coolmax\", \"memory upgrades\", \"patriot\", \"buffalo\", \"centon\", \"chief\", \"chief manufacturing\", \"clickfree\", \"cobra\", \"comprehensive\", \"comprehensive video\", \"coolguard\", \"cp tech\", \"cp technology\", \"crown\", \"edge\", \"eforcity\", \"ep memory\", \"eveready\", \"focus\"],\n",
    "        \"Mobile Devices\": [\"htc\", \"jabra\", \"samsung\", \"sony\", \"nokia\", \"apple\", \"blackberry\", \"motorola\", \"mybat\", \"coby\", \"lg\", \"vtech\"],\n",
    "        \"Audio & Video\": [\"audio-technica\", \"bose\", \"jvc\", \"pioneer\", \"plantronics\", \"sony\", \"audiovox\", \"audiosource\", \"axis\", \"axis communications\", \"boss\", \"creative\", \"crosley\", \"diamond\", \"jaton\", \"razer\", \"sennheiser\", \"sharp\", \"skullcandy\", \"creative labs\", \"hercules\", \"ihome\", \"elite\", \"matic\", \"clarion mobile electronics\", \"dj tech\", \"dj-tech\", \"fanatics\", \"philips\", \"rca\", \"sirius\", \"sirius satellite radio\"],\n",
    "        \"Networking\": [\"cisco\", \"d-link\", \"linksys\", \"netgear\", \"tp-link\", \"zyxel\", \"actiontec\", \"trendnet\", \"trendware\", \"amp\", \"amped wireless\", \"link depot\", \"syba\", \"syba multimedia\", \"netopia\", \"u.s. robotics\"],\n",
    "        \"Storage Devices\": {\n",
    "            \"Internal Storage\": [\"seagate\", \"western digital\", \"toshiba\", \"crucial\", \"ocz\", \"ocz technologies\", \"quantum\", \"transcend\", \"edge tech\"],\n",
    "            \"External Storage\": [\"sandisk\", \"kingston\", \"lacie\", \"buffalo\", \"cavalry\", \"buslink\", \"apricorn\", \"iomega\", \"pny\"]\n",
    "        }\n",
    "    },\n",
    "    \"Office Supplies\": {\n",
    "        \"Paper Products\": [\"hammermill\", \"smead\", \"avery\", \"cardinal\", \"pendaflex\", \"boise\", \"domtar\", \"pacon\", \"pacon products\", \"boise cascade\", \"tops business forms\"],\n",
    "        \"Writing Instruments\": [\"bic\", \"sharpie\", \"pilot\", \"papermate\", \"uniball\", \"prismacolor\", \"expo\", \"tops\", \"pentel\", \"pentel of america ltd.\", \"stabilo\"],\n",
    "        \"Organization\": [\"wilson jones\", \"officemate\", \"post-it\", \"swingline\", \"bankers box\", \"buddy products\", \"c-line\", \"smead manufacturing company\", \"rolodex\", \"globe weis\", \"ghent\", \"safco products\"],\n",
    "        \"Other Office Supplies\": [\"acco\", \"buddy products\", \"dixie\", \"rubbermaid\", \"samsill\", \"bond street\", \"bond street ltd.\", \"elmer s\", \"exact\", \"staples\", \"at t\", \"avery personal creations\", \"paperpro\", \"redi-tag\"]\n",
    "    },\n",
    "    \"Accessories\": {\n",
    "        \"Computer Accessories\": [\"accessory power\", \"belkin\", \"case logic\", \"kensington\", \"targus\", \"brenthaven\", \"cables to go\", \"cables unlimited\", \"iogear\", \"zagg\", \"otterbox\", \"incipio\", \"griffin\", \"vantec\", \"logitech\", \"cooler master\", \"coolermaster\", \"pluggable technologies\", \"siig\", \"planar\", \"planar systems\", \"plugable technologies\"],\n",
    "        \"Mobile Accessories\": [\"zagg\", \"otterbox\", \"speck\", \"incipio\", \"griffin\", \"blueant\", \"iluv\", \"amzer\", \"just mobile\", \"bluelounge\", \"bluelounge design\", \"roadwired\"],\n",
    "        \"Photography Accessories\": [\"lowepro\", \"moshi\", \"manfrotto\", \"tamron\", \"sigma\", \"ape case\", \"dolica\", \"tiffen\", \"tenba\", \"zeikos\", \"arkon\", \"arrowmounts\", \"bower\", \"platt\", \"platt cases\", \"sima\", \"golla\", \"humminbird\"]\n",
    "    },\n",
    "    \"Software\": {\n",
    "        \"Operating Systems\": [\"microsoft\"],\n",
    "        \"Creative Tools\": [\"adobe\", \"encore software\", \"acd\", \"acd systems\", \"avid technology\", \"roxio\", \"serif\", \"the learning company\"],\n",
    "        \"Security\": [\"symantec\", \"webroot\", \"mcafee\", \"kaspersky\"],\n",
    "        \"Utilities\": [\"avg\", \"norton\", \"ccleaner\", \"winrar\", \"plustek\", \"neosafe\", \"advanced system care\", \"iosafe\"]\n",
    "    },\n",
    "    \"Consumer Electronics\": {\n",
    "        \"Audio\": [\"bose\", \"audio-technica\", \"plantronics\", \"skullcandy\", \"sony\", \"aztec\", \"soundstorm\", \"fellowes\", \"cyber acoustics\", \"ultimate ears\"]\n",
    "    },\n",
    "    \"Printing & Imaging\": {\n",
    "        \"Printers\": [\"brother\", \"canon\", \"epson\", \"hp\", \"xerox\", \"oki\", \"lexmark\", \"dymo\"],\n",
    "        \"Cameras\": [\"nikon\", \"olympus\", \"panasonic\", \"sony\", \"vivitar\", \"fujifilm\", \"kodak\", \"polaroid\", \"fuji\", \"garmin\"],\n",
    "        \"Projectors\": [\"optoma\", \"benq\", \"epson\", \"nec\", \"hitachi\", \"elite screens\", \"viewsonic\", \"sunpak\"]\n",
    "    },\n",
    "    \"Home Appliances\": {\n",
    "        \"Small Appliances\": [\"black & decker\", \"dyson\", \"kitchenaid\", \"cuisinart\", \"allied\", \"haier\", \"emerson\", \"magna visual\", \"keurig\"]\n",
    "    },\n",
    "    \"Entertainment\": {\n",
    "        \"Characters\": [\"disney\", \"hello kitty\"],\n",
    "        \"Media\": [\"sirius xm\", \"spotify\", \"pandora\", \"ilive\", \"flip video\", \"eye-fi\", \"favi entertainment\", \"vizio\", \"sirius\", \"sirius satellite radio\"]\n",
    "    },\n",
    "    \"Miscellaneous\": {\n",
    "        \"General\": [\"generic\", \"unknown\", \"3m #\", \"blue crane digital\", \"black n  red\", \"green onions supply\", \"u.s. brown bear\", \"universal\", \"americopy\", \"dealz4real\", \"egpchecks\", \"add on\", \"sage\", \"sumas\"],\n",
    "        \"Multi-Category\": [\"3m\", \"amazonbasics\", \"anker\", \"eco-products\", \"advantus\", \"acs\", \"casio\", \"ford\"]\n",
    "    },\n",
    "    \"Uncategorized\": [\"accessorieszone\", \"agf\", \"action\", \"adesso\", \"alama\", \"aluratek\", \"antec\", \"balt\", \"best rite\", \"booq\", \"brainydeal\", \"bti\", \"bushnell\", \"compatible\", \"digital concepts\", \"dreamgear\", \"duracell\", \"energizer\", \"evga\", \"ifixit\", \"joby\", \"kensmart\", \"lowrance\", \"macsense\", \"marware\", \"mivizu\", \"msi\", \"mustang\", \"namo\", \"nuance\", \"penpower\", \"quartet\", \"storex\", \"think outside\", \"treque\", \"tribeca\", \"tripp lite\", \"trodat\", \"v7\", \"vaultz\", \"writeright\", \"zalman\", \"clarion\", \"clarion software\", \"simplism\", \"cocoon\", \"cocoon innovations\", \"compucessory\", \"concord\", \"csdc\", \"cta\", \"cta digital\", \"curtis\", \"cyberpower\", \"da-lite\", \"da-lite screen\", \"defender\", \"deluxe\", \"diaper dude\", \"digipower\", \"digital innovations\", \"digital peripheral solutions\", \"directed electronics\", \"discgear\", \"dp audio video\", \"dp video\", \"draper\", \"eaton\", \"elago\", \"electrified\", \"ematic\", \"emerge tech\", \"encore\", \"endust\", \"eveready\", \"fantom\", \"franklin\", \"franklin electronics\", \"gator\", \"gator cases\", \"gbc\", \"ge\", \"gear head\", \"general electric\", \"genius\", \"genuine phillips\", \"global marketing\", \"global marketing partners\", \"gn netcom\", \"goodhope bags\", \"gpx\", \"grade-a\", \"greatshield\", \"green\", \"griffin technology\", \"grt\", \"guardian\", \"hewcpn\", \"hon\", \"hqrp\", \"human toolz\", \"humantoolz\", \"i concepts\", \"i-tec\", \"i-tec electronics\", \"i.sound\", \"ifrogz\", \"igo\", \"imation\", \"inland\", \"inland pro\", \"innergie\", \"innovera\", \"iosafe inc\", \"iris\", \"iriver\", \"itw\", \"itw dymon\", \"ivina\", \"jawbone\", \"jwin\", \"kanguru\", \"kanguru solutions\", \"karendeals\", \"kenwood\", \"keyspan\", \"keytronicems\", \"kimberly-clark\", \"kimberly-clark professional\", \"kinamax\", \"kingsmart\", \"kingwin\", \"kiq\", \"konica-minolta\", \"koss\", \"labtec\", \"lanthem\", \"lathem\", \"lexar\", \"lexar media\", \"lifeworks\", \"lorex\", \"lumiere l.a.\", \"lumiere la\", \"luxor\", \"macally\", \"maccase\", \"mace\", \"mace security\", \"mach speed\", \"magnavox\", \"manhattan\", \"master caster\", \"maxell\", \"mayline\", \"mead\", \"memorex\", \"memtek\", \"mercury\", \"mercury luggage\", \"merkury\", \"merkury innovations\", \"metra\", \"micro innovations\", \"micronet\", \"middle atlantic\", \"midland\", \"mionix\", \"mmf\", \"mobile edge\", \"mohawk\", \"molex\", \"motion systems\", \"mukii\", \"mygear products\", \"nan\", \"national\", \"national products ltd.\", \"navgear\", \"neat receipts\", \"neatreceipts\", \"next web sales\", \"nextware\", \"night owl\", \"night owl optics\", \"norazza\", \"nxg\", \"nxg technology\", \"nzxt\", \"office star\", \"oki data\", \"omnimount\", \"orbital\", \"oxford\", \"p3 international\", \"p3 international corporation\", \"paper mate\", \"pc treasures\", \"peak\", \"peerless\", \"pelican\", \"pelican storm\", \"pelouze\", \"pentel of america ltd.\", \"performance plus\", \"planar\", \"planar systems\", \"plugable technologies\", \"pm company\", \"power mat\", \"power mate\", \"powermat\", \"premiertek\", \"primera technology\", \"pyle\", \"pyramid\", \"q-see\", \"quality park\", \"raptor\", \"raptor-gaming\", \"rayovac\", \"read right\", \"rim\", \"riteav\", \"roocase\", \"royal\", \"royal consumer\", \"s j paper\", \"sabrent\", \"saitek\", \"sakar\", \"sanford\", \"sanrio\", \"sanus\", \"sanyo\", \"sapphire\", \"scosche\", \"scotch\", \"seal shield\", \"seiko\", \"seiko instruments\", \"sentry\", \"sgp\", \"shopforbattery\", \"simplism japan\", \"siskiyou\", \"skooba design\", \"slappa\", \"slik\", \"smartbuy\", \"smk\", \"solidtek\", \"solo\", \"sonnet technologies\", \"sonnet technologies inc\", \"sparco\", \"spectrum brands\", \"srs\", \"srs labs\", \"stanley\", \"stanley bostitch\", \"startech\", \"startech.com\", \"startech.com usa llp\", \"steelseries\", \"storm\", \"sumas media\", \"sumdex\", \"sunvalleytek\", \"super talent\", \"svat\", \"svat electronics\", \"swann\", \"sylvania\", \"t-mobile\", \"talk works\", \"tandberg\", \"team pro mark\", \"team promark\", \"team promark llc\", \"tektronix\", \"ten\", \"ten one design\", \"terk\", \"the joy factory\", \"thermaltake\", \"tomtom\", \"tp link\", \"tracfone\", \"tvtimedirect\", \"ultralast\", \"uniden\", \"universal products\", \"us brown bear\", \"usrobotics\", \"veho\", \"verbatim\", \"victor\", \"victory\", \"victory multimedia\", \"vipertek\", \"visioneer\", \"visiontek\", \"vistablet\", \"visual land\", \"vonnic inc\", \"wacom\", \"wacom tech corp.\", \"wausau\", \"wausau paper\", \"weyerhauser\", \"whistler\", \"whistler radar\", \"wincraft\", \"wintec\", \"x-acto\", \"x16-81686-03\", \"xantech\", \"xfx\", \"xgear\", \"xo vision\", \"xtrememac\", \"zalman usa inc\", \"zax\", \"zebra\", \"zoom\", \"zoom telephonics\", \"zotac\", \"zune\"],\n",
    "    'UNK':[\"aiptek\", \"alera\", \"aleratec\", \"alkaline\", \"allsop\", \"amp energy\", \"ampad\", \"arclyte technologies inc. .\", \"atrend-bbox\", \"bell  o\", \"bravo\", \"bravo view\", \"buddy\", \"can-c\", \"channel sources\", \"clover\", \"clover electronics\", \"cms\", \"curo7\", \"pentel of america ltd. .\"]\n",
    "}\n",
    "category_hierarchy = {\n",
    "    \"Electronics\": {\n",
    "        \"Audio\": {\n",
    "            \"Cables\": [\"audio cables\", \"speaker cables\", \"rca cables\", \"video cables\", \"cables interconnects\", \"power cables\"],\n",
    "            \"Mobile Phones\": [\"prepaid wireless phones\", \"unlocked cell phones\", \"smartphones\", \"phones\", \"feature phones\", \"corded telephones\", \"cordless telephones\", \"phones with plans\", \"unlocked phones\", \"no-contract phones\"],\n",
    "            \"Car Audio\": [\"audio car mounts\", \"car audio video\", \"car stereos\", \"bluetooth car kits\", \"auxiliary input adapters\", \"audio-video kits\", \"car kits\", \"radio antennas\", \"equalizers\"],\n",
    "            \"Speakers\": [\"stereos/audio\", \"coaxial speakers\", \"speakers\", \"subwoofers\", \"component subwoofers\", \"speaker systems\", \"speaker parts components\", \"subwoofer boxes and enclosures\", \"boomboxes\"],\n",
    "            \"Accessories\": [\"amplifier installation\", \"amplifier wiring kits\", \"speaker installation\", \"mp3 accessories\", \"speaker connectors\", \"bluetooth headsets\", \"universal fm cassette adapters\", \"mp3 player accessories\", \"mp3 player cables adapters\", \"headsets\", \"wired headsets\", \"headsets microphones\", \"microphones accessories\", \"touch screen tablet accessories\"],\n",
    "            \"General\": [\"audio video accessories\", \"computers accessories\", \"phone accessories\", \"electronics-inflexible kit\", \"satellite radios\", \"satellite radio\", \"antennas\", \"handheld portable satellite radios\", \"plug play satellite radios\", \"component video\", \"stereos\", \"answering devices\", \"caller id displays\", \"corded-cordless combo telephones\"]\n",
    "        },\n",
    "        \"Cameras\": {\n",
    "            \"Types\": [\"digital cameras\", \"film cameras\", \"hidden cameras\", \"game cameras\", \"bullet cameras\", \"dome cameras\", \"simulated cameras\", \"camcorders\", \"dslr cameras\", \"digital slr cameras\", \"digital slr camera bundles\", \"point shoot digital cameras\", \"point shoot digital camera bundles\", \"film\"],\n",
    "            \"Accessories\": [\"camera batteries\", \"lens accessories\", \"tripods\", \"camera and camcorder accessories\", \"camera lenses\", \"binocular accessories\", \"filters\", \"camera bags\", \"camcorder batteries\", \"photo video design\", \"digital camera accessories\", \"flashes\", \"complete tripod units\", \"professional video accessories\", \"webcams\", \"external floppy drives\", \"faceplates\", \"screen filters\"],\n",
    "            \"General\": [\"camera photo\", \"binoculars\"]\n",
    "        },\n",
    "        \"Computing\": {\n",
    "            \"Components\": [\"motherboards\", \"graphics cards\", \"hard drives\", \"internal hard drives\", \"external hard drives\", \"internal optical drives\", \"internal sound cards\", \"computer components\", \"memory\", \"memory cards\", \"usb port cards\", \"network cards\", \"case fans\", \"video capture cards\", \"optical drives\", \"hard drive enclosures\", \"firewire port cards\", \"internal dvd drives\", \"i o port cards\", \"floppy diskettes\"],\n",
    "            \"Accessories\": [\"keyboard mouse combos\", \"mouse pads\", \"computers\", \"laptop computers\", \"monitor arms stands\", \"computer cases\", \"cooling pads\", \"usb cables\", \"power supplies\", \"computer accessories\", \"memory card readers\", \"memory card adapters\", \"monitors\", \"mice\", \"gaming mice\", \"modems\", \"scsi port cards\", \"computer cable adapters\", \"computer monitor mounts\", \"computer speakers\", \"cases\", \"keyboards\", \"laptops\", \"netbooks\", \"trackballs\", \"touch pads\", \"headphones\", \"headphone accessories\", \"desktops\", \"keyboards mice input devices\", \"keyboards styluses\", \"laptop netbook computer accessories\", \"tablet accessories\", \"docking stations\", \"graphics tablets\", \"monitor accessories\", \"mounts\", \"tablets\", \"ipod\"],\n",
    "            \"Software\": [\"operating systems\", \"productivity software\", \"security software\", \"graphic design software\", \"development tools\", \"software\"]\n",
    "        },\n",
    "        \"Networking\": {\n",
    "            \"Devices\": [\"routers\", \"walkie-talkie/frs\", \"network adapters\", \"wireless access points\", \"modems\", \"powerline network adapters\", \"print servers\", \"switches\", \"network attached storage\", \"frs two-way radios\", \"gmrs-frs two-way radios\", \"two-way radios accessories\", \"kvm switches\", \"usb network adapters\", \"networking products\"],\n",
    "            \"Cables\": [\"ethernet cables\", \"usb cables\", \"data cables\", \"firewire cables\", \"scsi cables\", \"dvi cables\", \"hdmi cables\", \"charger cables\", \"chargers cables\"]\n",
    "        },\n",
    "        \"Televisions\": {\n",
    "            \"TVs\": [\"tvs\", \"television\", \"televisions video\", \"overhead video\"],\n",
    "            \"Accessories\": [\"tv mounts\", \"projection screens\", \"television stands entertainment centers\", \"video projectors\", \"video projector accessories\", \"remote controls\", \"remote-control extenders\", \"tv accessories\", \"video glasses\", \"projector accessories\", \"projector mounts\", \"video converters\", \"video receiving & installation\", \"video transmission systems\", \"controllers\"]\n",
    "        },\n",
    "        \"General\": [\"electronics - general\", \"networking\", \"office electronics\", \"office electronics accessories\", \"hubs\", \"components\", \"power strips\", \"cleaning repair\", \"distribution panels\", \"electronics\", \"electronics : flat panel tv\", \"audio-video shelving\", \"impact dot matrix printer ribbons\", \"electrical\", \"distribution\", \"surge protectors\", \"uninterrupted power supply ups\", \"laser printers\", \"printing\"]\n",
    "    },\n",
    "    \"Office Supplies\": {\n",
    "        \"Paper Products\": [\"laminating supplies\", \"business cards\", \"memo scratch pads\", \"labels stickers\", \"postcards\", \"wide-format paper\", \"business paper products\", \"colored paper\", \"file folder labels\", \"roll paper\", \"shipping labels\", \"address labels\", \"continuous-form labels\", \"all-purpose labels\", \"photo paper\", \"paper\"],\n",
    "        \"Furnitures\": [\"furniture\", \"desks\", \"chairs\", \"file cabinets\", \"office furniture lighting\", \"hanging folders interior folders\", \"footrests\", \"stands\", \"wrist rests\"],\n",
    "        \"Electronics\": [\"printers\", \"scanners\", \"shredders\", \"fax machines\", \"inkjet all-in-one printers\", \"laser all-in-one printers\", \"digital security recorders\", \"all-in-one printers\", \"projection screens\", \"desktop staplers\", \"telephone accessories\", \"scanner accessories\", \"label makers\", \"postal scales\"],\n",
    "        \"Printer Accessories\": [\"printer accessories\", \"inkjet printer ink\", \"laser printer toner\", \"printer ink toner\", \"printer labels laser inkjet\", \"printer staples\", \"printer roll holders\", \"printer transfer rollers\", \"printer transfer units\", \"inkjet printer paper\"],\n",
    "        \"Stationery\": [\"self-stick notes\", \"lamps\", \"pen holders\", \"stationery & office machinery\", \"labeling tapes\", \"binder index dividers\", \"looseleaf binder paper\", \"labels stickers\", \"badge holders\", \"storage presentation materials\", \"document creation\", \"view binders\", \"english dictionaries\", \"self-stick note pad holders\", \"flowcharts\", \"portfolios\", \"presentation pointers\", \"presentation remotes\", \"index dividers\"]\n",
    "    },\n",
    "    \"Automotive\": {\n",
    "        \"Electronics\": [\"dash mounting kits\", \"radar detectors\", \"gps\", \"handheld gps\", \"vehicle gps\", \"portable vehicle gps\", \"in-dash navigation\", \"audio-video kits\", \"gps system accessories\", \"car electronics\"],\n",
    "        \"Accessories\": [\"car chargers\", \"vehicle mounts\", \"back seat cushions\", \"car cradles\", \"dash mounting kits\", \"wiring harnesses\", \"auxiliary input adapters\", \"cb radios\", \"antitheft\", \"car electronics accessories\"],\n",
    "        \"General\": [\"automotive - general\"]\n",
    "    },\n",
    "    \"Batteries\": {\n",
    "        \"Types\": [\"12v\", \"6v\", \"9v\", \"aa\", \"aaa\", \"coin button cell\", \"batteries\"],\n",
    "        \"Accessories\": [\"battery chargers\", \"charger cables\", \"chargers adapters\", \"household batteries\", \"batteries chargers accessories\", \"desktop chargers\", \"ac adapters\", \"chargers\"]\n",
    "    },\n",
    "    \"Media\": {\n",
    "        \"Storage\": [\"storage\", \"cd-r discs\", \"dvd r discs\", \"usb flash drives\", \"usb drives\", \"external data storage\", \"data cartridges\", \"dvd rw discs\", \"bd-r discs\", \"blank media\", \"cd-rw discs\", \"dvd-ram discs\", \"dlt cleaning cartridges\", \"media storage organization\", \"disc jewel cases\", \"disc storage wallets\", \"dvd-r discs\"],\n",
    "        \"Devices\": [\"blu-ray disc players\", \"mp3 players\", \"portable dvd players\", \"dvd players\", \"dvd accessories\", \"upconverting dvd players\", \"disc players recorders\", \"mp3\", \"portable audio\", \"cd players\", \"cd-mp3 players\", \"digital media devices\", \"changers\"]\n",
    "    },\n",
    "    \"Home & Security\": {\n",
    "        \"Home Theater\": [\"dvd home theater\", \"home theater systems\", \"home theater\", \"stereo amplifiers\", \"home audio theater\", \"home audio crossovers\", \"turntables\"],\n",
    "        \"Security\": [\"home care\", \"home security systems\", \"surveillance cameras\", \"security surveillance\", \"security sensors alarms\", \"complete surveillance systems\", \"hidden cameras\", \"household sensors alarms\", \"simulated cameras\", \"security monitors displays\", \"surveillance video recorders\"],\n",
    "        \"General\": [\"house wares\"]\n",
    "    },\n",
    "    \"Accessories\": {\n",
    "        \"General\": [\"bags cases\", \"covers skins\", \"armbands\", \"cases sleeves\", \"handbags\", \"camera bags\", \"accessories\", \"accessories supplies\", \"accessories apparel\", \"accessory kits\", \"cases bags\", \"hard drive bags\", \"projector bags cases\", \"covers\", \"armbands\", \"styli\", \"screen protectors\", \"screen protector foils\", \"wall chargers\", \"laser pointers\"]\n",
    "    },\n",
    "    \"Tools\": {\n",
    "        \"General\": [\"toolkits\", \"power strips\", \"cable security devices\", \"cleaning repair\", \"binding machines\", \"binding machine supplies\", \"adapters\", \"connectors adapters\", \"adapter rings\", \"distribution panels\", \"wire management\", \"power adapters\", \"power converters\", \"power ground cable\", \"power inverters\", \"power-cable terminals\", \"selector boxes\", \"switchers\"]\n",
    "    },\n",
    "    \"Photography\": {\n",
    "        \"Cameras\": [\"point shoot digital cameras\", \"dslr cameras\", \"camcorders\", \"digital slr cameras\", \"digital slr camera bundles\", \"point shoot digital camera bundles\"],\n",
    "        \"Accessories\": [\"filters\", \"camera bags\", \"tripods\", \"camera batteries\", \"camera lenses\", \"flashes\", \"lens accessories\", \"complete tripod units\", \"professional video accessories\"],\n",
    "        \"General\": [\"photography - general\", \"photo editing\", \"media storage organization\"]\n",
    "    },\n",
    "    \"Other\": {\n",
    "        \"General\": [\"scientific\", \"fan shop\", \"rugs\", \"toys - games\", \"garden - general\", \"sports outdoor gps\", \"hiking gps units\", \"boating gps units chartplotters\", \"fish finder\", \"fishfinders\", \"fishing and boating\", \"nan\", \"personal care\", \"other office equipment\", \"outlet plates\", \"wall plates connectors\", \"radios\", \"basic\", \"bundles\", \"c\", \"d\", \"hardware\", \"lighting\", \"pda handheld accessories\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_mask(df,frac):\n",
    "    L = len(COL)*len(df)\n",
    "    L_disturb = int(np.ceil(L*frac))\n",
    "    disturb_mask = np.zeros((len(df),len(COL)))\n",
    "    total_elements = disturb_mask.size\n",
    "    random_indices = np.random.choice(total_elements, L_disturb, replace=False)\n",
    "    disturb_mask.flat[random_indices] = 1\n",
    "    return disturb_mask \n",
    "\n",
    "\n",
    "def find_parents(hierarchy, target, parents=None):\n",
    "    if parents is None:\n",
    "        parents = []\n",
    "\n",
    "    for key, value in hierarchy.items():\n",
    "        if key == target:  # If the target itself is a key\n",
    "            return parents + [key]\n",
    "        if isinstance(value, dict):  # If value is a nested dictionary\n",
    "            result = find_parents(value, target, parents + [key])\n",
    "            if result != -1:\n",
    "                return result\n",
    "        elif isinstance(value, list) and target in value:  # If value is a list containing the target\n",
    "            return parents + [key]\n",
    "\n",
    "    return -1  # Return -1 if the target is not found\n",
    "\n",
    "\n",
    "def disturb_func(col,value):\n",
    "    if col =='brand':\n",
    "        \n",
    "        parents = find_parents(brand_hierarchy, str(value).lower().strip())\n",
    "        if parents == -1: print(value)\n",
    "        new_seed = int(time.time())\n",
    "        np.random.seed(new_seed)\n",
    "        np.random.shuffle(parents)\n",
    "        new_velue = parents[0]\n",
    "        \n",
    "\n",
    "    elif col == 'category':\n",
    "        parents = find_parents(category_hierarchy, str(value).lower().strip())\n",
    "        if parents == -1: print(value)\n",
    "        new_seed = int(time.time())\n",
    "        np.random.seed(new_seed)\n",
    "        np.random.shuffle(parents)\n",
    "        new_velue = parents[0]\n",
    "\n",
    "    elif col =='price':\n",
    "        if str(value) =='nan':\n",
    "            new_velue = 'other'\n",
    "\n",
    "        else:\n",
    "                        \n",
    "            data = [float(value)]\n",
    "            number_hierarchy = {\n",
    "                \"Ranges\": {\n",
    "                    \"Very Low\": {\n",
    "                        \"0-0.49\": [n for n in data if 0 <= n < 0.5],\n",
    "                        \"0.5-0.99\": [n for n in data if 0.5 <= n < 1]\n",
    "                    },\n",
    "                    \"Low\": {\n",
    "                        \"1-4.99\": [n for n in data if 1 <= n < 5],\n",
    "                        \"5-9.99\": [n for n in data if 5 <= n < 10]\n",
    "                    },\n",
    "                    \"Moderate\": {\n",
    "                        \"10-49.99\": [n for n in data if 10 <= n < 50],\n",
    "                        \"50-99.99\": [n for n in data if 50 <= n < 100]\n",
    "                    },\n",
    "                    \"High\": {\n",
    "                        \"100-499.99\": {\n",
    "                            \"100-199.99\": [n for n in data if 100 <= n < 200],\n",
    "                            \"200-299.99\": [n for n in data if 200 <= n < 300],\n",
    "                            \"300-399.99\": [n for n in data if 300 <= n < 400],\n",
    "                            \"400-499.99\": [n for n in data if 400 <= n < 500]\n",
    "                        },\n",
    "                        \"500-999.99\": {\n",
    "                            \"500-749.99\": [n for n in data if 500 <= n < 750],\n",
    "                            \"750-999.99\": [n for n in data if 750 <= n < 1000]\n",
    "                        }\n",
    "                    },\n",
    "                    \"Very High\": {\n",
    "                        \"1000-4999.99\": {\n",
    "                            \"1000-1999.99\": [n for n in data if 1000 <= n < 2000],\n",
    "                            \"2000-2999.99\": [n for n in data if 2000 <= n < 3000],\n",
    "                            \"3000-3999.99\": [n for n in data if 3000 <= n < 4000],\n",
    "                            \"4000-4999.99\": [n for n in data if 4000 <= n < 5000]\n",
    "                        },\n",
    "                        \"5000 and above\": {\n",
    "                            \"5000-9999.99\": [n for n in data if 5000 <= n < 10000],\n",
    "                            \"10000 and above\": [n for n in data if n >= 10000]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \n",
    "            }\n",
    "            if find_parents(number_hierarchy, float(value)) ==-1:\n",
    "                print(value, type(value))\n",
    "            parents = find_parents(number_hierarchy, float(value))[1:]\n",
    "\n",
    "            new_seed = int(time.time())\n",
    "            np.random.seed(new_seed)\n",
    "            np.random.shuffle(parents)\n",
    "            new_velue = parents[0]\n",
    "        \n",
    "    return new_velue\n",
    "\n",
    "\n",
    "\n",
    "# /home/mmoslem3/DATA_VLDB/Fodors-Zagat/\n",
    "\n",
    "task = 'Walmart-Amazon'\n",
    "COL = ['category','brand','price']\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "for frac in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "    L =[]\n",
    "    for rep in range(1,101):\n",
    "        df = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/data/\" + task  +'/test.csv')\n",
    "\n",
    "        mask_left = make_mask(df,frac)\n",
    "        mask_right = make_mask(df,frac)\n",
    "        df['left_price'] = df['left_price'].astype(str)\n",
    "        df['right_price'] = df['right_price'].astype(str)\n",
    "        x = 0\n",
    "        for i,col in enumerate(COL):\n",
    "            df.loc[mask_left[:,i] == 1, 'left_'+col] = df.loc[mask_left[:,i] == 1, 'left_'+col].apply(lambda x: disturb_func(col, x))\n",
    "            df.loc[mask_right[:,i] == 1, 'right_'+col] = df.loc[mask_right[:,i] == 1, 'right_'+col].apply(lambda x: disturb_func(col, x))\n",
    "\n",
    "            x+=(column_entropy(df['left_'+col]) +column_entropy(df['right_'+col]))\n",
    "\n",
    "        L.append(x)\n",
    "    if frac ==0:\n",
    "        base = np.average(L).copy()\n",
    "    base =1\n",
    "    print(round(np.average(L)/base,2), round(np.sqrt(np.std(L))/base,2))\n",
    "\n",
    "print('walamrt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.84 0.0\n",
      "33.98 0.23\n",
      "34.23 0.75\n",
      "33.89 0.0\n",
      "31.82 0.47\n",
      "29.15 1.09\n",
      "21.33 0.66\n",
      "17.9 0.0\n",
      "itun\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "date_hierarchy = {\n",
    "    '1980s': {\n",
    "        '1987': {\n",
    "            '1987September': ['1987/September/23']\n",
    "        }\n",
    "    },\n",
    "    '1990s': {\n",
    "        '1990': {\n",
    "            '1990January': ['1990/January/01']\n",
    "        },\n",
    "        '1994':[],\n",
    "        '1997':[],\n",
    "        '1995': {\n",
    "            '1995June': ['1995/June/13']\n",
    "        },\n",
    "        '1999': {\n",
    "            '1999May': ['1999/May/17'],\n",
    "            '1999October': ['1999/October/19']\n",
    "        }\n",
    "    },\n",
    "    '2000s': {\n",
    "        '2000': {\n",
    "            '2000August': ['2000/August/17'],\n",
    "            '2000September': ['2000/September/26']\n",
    "        },\n",
    "        '2002': {\n",
    "            '2002April': ['2002/April/02']\n",
    "        },\n",
    "        '2003': {\n",
    "            '2003May': ['2003/May/20', '2003/May/27'],\n",
    "            '2003August': ['2003/August/29'],\n",
    "            '2003November': ['2003/November/11']\n",
    "        },\n",
    "        '2004': {\n",
    "            '2004February': ['2004/February/02', '2004/February/10'],\n",
    "            '2004July': ['2004/July/27'],\n",
    "            '2004November': ['2004/November/16']\n",
    "        },\n",
    "        '2005': {\n",
    "            '2005September': ['2005/September/20'],\n",
    "            '2005October': ['2005/October/04'],\n",
    "            '2005November': ['2005/November/07', '2005/November/22']\n",
    "        },\n",
    "        '2006': {\n",
    "            '2006April': ['2006/April/04'],\n",
    "            '2006June': ['2006/June/20'],\n",
    "            '2006October':['2006/October/24'],\n",
    "            '2006March':['2006/March/04']\n",
    "\n",
    "        },\n",
    "        '2007': {\n",
    "             '2007September':['2007/September/18'],\n",
    "            '2007February': ['2007/February/06'],\n",
    "            '2007March': ['2007/March/16'],\n",
    "            '2007July': ['2007/July/10'],\n",
    "            '2007August': ['2007/August/14'],\n",
    "            '2007November': ['2007/November/20']\n",
    "        },\n",
    "        '2008': {\n",
    "            '2008March': ['2008/March/17', '2008/March/18'],\n",
    "            '2008June': ['2008/June/23', '2008/June/24'],\n",
    "            '2008July': ['2008/July/15', '2008/July/29'],\n",
    "            '2008August': ['2008/August/01'],\n",
    "            '2008October': ['2008/October/21', '2008/October/28'],\n",
    "            '2008November': ['2008/November/04', '2008/November/11']\n",
    "        },\n",
    "        '2009': {\n",
    "            '2009March': ['2009/March/30'],\n",
    "            '2009April': ['2009/April/17'],\n",
    "            '2009September':['2009/September/15'],\n",
    "            '2009May': ['2009/May/05'],\n",
    "            '2009August': ['2009/August/21'],\n",
    "            '2009October': ['2009/October/02'],\n",
    "            '2009November': ['2009/November/03', '2009/November/23'],\n",
    "            '2009December': ['2009/December/21']\n",
    "        }\n",
    "    },\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '2010s': {\n",
    "        '2010': {\n",
    "             \n",
    "            '2010June': ['2010/June/15', '2010/June/16', '2010/June/21'],\n",
    "            '2010August': ['2010/August/03'],\n",
    "            '2010October': ['2010/October/25'],\n",
    "            '2010November': ['2010/November/24', '2010/November/26'],\n",
    "            '2010December': ['2010/December/14', '2010/December/21','2010/December/03']\n",
    "        },\n",
    "        '2011': { \n",
    "             \n",
    "\n",
    "\n",
    "\n",
    "            '2011January': ['2011/January/14'],\n",
    "            '2011February': ['2011/February/08', '2011/February/14', '2011/February/22'],\n",
    "            '2011March': ['2011/March/08', '2011/March/28', '2011/March/29'],\n",
    "            '2011April': ['2011/April/18', '2011/April/26','2011/April/19'],\n",
    "            '2011May': ['2011/May/23', '2011/May/25', '2011/May/27'],\n",
    "            '2011June': ['2011/June/07'],\n",
    "            '2011July': ['2011/July/14', '2011/July/22','2011/July/19'],\n",
    "            '2011August': ['2011/August/23', '2011/August/26'],\n",
    "            '2011September': ['2011/September/09', '2011/September/16', '2011/September/30'],\n",
    "            '2011November': ['2011/November/15', '2011/November/21'],\n",
    "            '2011December': ['2011/December/06', '2011/December/09', '2011/December/16', '2011/December/20', '2011/December/27','2011/December/12']\n",
    "        },\n",
    "        '2012': {\n",
    "             \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            '2012January': ['2012/January/20'],\n",
    "            '2012February': ['2012/February/22'],\n",
    "            '2012March': ['2012/March/20', '2012/March/23'],\n",
    "            '2012April': ['2012/April/24','2012/April/17'],\n",
    "            '2012May':['2012/May/11'],\n",
    "            '2012June': ['2012/June/14', '2012/June/19', '2012/June/22'],\n",
    "            '2012July': ['2012/July/02', '2012/July/31'],\n",
    "            '2012August': ['2012/August/09', '2012/August/28'],\n",
    "            '2012September':['2012/September/11'],\n",
    "            '2012October': ['2012/October/09', '2012/October/30'],\n",
    "            '2012November': ['2012/November/09', '2012/November/13'],\n",
    "            '2012December': ['2012/December/04']\n",
    "        },\n",
    "        '2013': {\n",
    "            '2013January': ['2013/January/04', '2013/January/18'],\n",
    "            '2013February': ['2013/February/05', '2013/February/12','2013/February/27'],\n",
    "            '2013March': ['2013/March/22', '2013/March/26'],\n",
    "            '2013April': ['2013/April/02', '2013/April/05', '2013/April/16'],\n",
    "            '2013May': ['2013/May/28'],\n",
    "            '2013June': ['2013/June/11'],\n",
    "            '2013July': ['2013/July/23'],\n",
    "            '2013August': ['2013/August/06', '2013/August/13', '2013/August/20', '2013/August/27'],\n",
    "            '2013September': ['2013/September/10', '2013/September/16', '2013/September/24', '2013/September/30'],\n",
    "            '2013November': ['2013/November/08', '2013/November/11', '2013/November/25'],\n",
    "            '2013December': ['2013/December/10', '2013/December/16']\n",
    "        },\n",
    "        '2014': {\n",
    "            '2014February': ['2014/February/18', '2014/February/24','2014/February/11'],\n",
    "            '2014April': ['2014/April/15'],\n",
    "            '2014May': ['2014/May/06', '2014/May/20', '2014/May/27','2014/May/02'],\n",
    "            '2014June': ['2014/June/02', '2014/June/04', '2014/June/20', '2014/June/23'],\n",
    "            '2014July':['2014/July/01','2014/July/07'],\n",
    "            '2014August': ['2014/August/19'],\n",
    "            '2014September': ['2014/September/09'],\n",
    "            '2014October': ['2014/October/14', '2014/October/21', '2014/October/27'],\n",
    "            '2014November': ['2014/November/04', '2014/November/10', '2014/November/24'],\n",
    "            '2014December': ['2014/December/23']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        },\n",
    "        '2015': {\n",
    "            '2015January': ['2015/January/09', '2015/January/13', '2015/January/21', '2015/January/30'],\n",
    "            '2015February': ['2015/February/13', '2015/February/24'],\n",
    "            '2015March': ['2015/March/03', '2015/March/10'],\n",
    "            '2015April': ['2015/April/06', '2015/April/10', '2015/April/17', '2015/April/21'],\n",
    "            '2015May': ['2015/May/12', '2015/May/15', '2015/May/18'],\n",
    "            '2015June': ['2015/June/01', '2015/June/03', '2015/June/09', '2015/June/16', '2015/June/22', '2015/June/23', '2015/June/30'],\n",
    "            '2015July': ['2015/July/01', '2015/July/03', '2015/July/10'],\n",
    "            '2015August': ['2015/August/07', '2015/August/10', '2015/August/28', '2015/August/31'],\n",
    "            '2015September': ['2015/September/04', '2015/September/11', '2015/September/18', '2015/September/21', '2015/September/25'],\n",
    "            '2015October': ['2015/October/09']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "genre_hierarchy = {\n",
    "    \"alternative rock\": [\n",
    "        \"alternative rock\",\n",
    "        \"alternative rock, indie & lo-fi\",\n",
    "        \"alternative, music, rock, adult alternative\"\n",
    "    ],\n",
    "    \"country\": [\n",
    "        \"country\",\n",
    "        \"country, contemporary country\",\n",
    "        \"country, country rock, pop, rock\",\n",
    "        \"country, country rock, rock\",\n",
    "        \"country, traditional country, cowboy\",\n",
    "        \"country, contemporary country, honky tonk\",\n",
    "        \"country, honky tonk, contemporary country\",\n",
    "        \"country, honky tonk, pop, pop/rock, contemporary country, rock\",\n",
    "        \"country, honky tonk, urban cowboy, contemporary country\",\n",
    "        \"country, music, pop, teen pop, honky tonk, contemporary country\",\n",
    "        \"country, music, rock, contemporary country, pop, pop/rock, honky tonk\",\n",
    "        \"country, music, urban cowboy, contemporary country\",\n",
    "        \"country, music, urban cowboy, honky tonk, contemporary country\",\n",
    "        \"country, music, contemporary country\",\n",
    "        \"country, music, contemporary country, honky tonk, traditional country\",\n",
    "\n",
    "\n",
    "                'country, music, honky tonk, contemporary country',\n",
    "                'country, music, honky tonk, pop, pop/rock, contemporary country, rock',\n",
    "                'country, music, honky tonk, urban cowboy, contemporary country'\n",
    "                \n",
    "\n",
    "    ],\n",
    "    \"dance & electronic\": [\n",
    "        \"dance & electronic\",\n",
    "        \"dance & electronic, dubstep\",\n",
    "        \"dance & electronic, house\",\n",
    "        \"dance & electronic, pop, house\",\n",
    "        \"dance & electronic, pop, r&b\",\n",
    "        \"dance & electronic, rap & hip-hop, house\",\n",
    "        \"dance, music\",\n",
    "        \"dance, music, electronic\",\n",
    "        \"dance, music, electronic, classical, classical crossover, rock, house, electronica\",\n",
    "        \"dance, music, electronic, house, rock, french pop\",\n",
    "        \"dance, music, pop\",\n",
    "        \"dance, music, r&b / soul, electronic\",\n",
    "        \"dance, music, rock\",\n",
    "        \"dance, music, rock, electronic\",\n",
    "        \"dance, music, rock, house, electronic\",\n",
    "        \"dance, music, rock, house, electronic, french pop\",\n",
    "        \"dance, music, rock, pop, house, electronic, electronica, adult alternative\",\n",
    "        \"dance, music, hip-hop / rap, alternative rap, hip-hop, r&b / soul, soul, electronic\",\n",
    "        \"dance, music, hip-hop / rap, dirty south, rap, electronic\",\n",
    "        'dance,music,hip-hop / rap, alternative rap,hip-hop, r&b / soul, soul, electronic',\n",
    "'dance,music,hip-hop / rap, dirty south, rap, electronic',\n",
    "    ],\n",
    "    \"electronica\": [\n",
    "        \"electronica, dance & electronic\",\n",
    "        \"electronica, dance & electronic, dubstep\",\n",
    "        \"electronica, dance & electronic, house\",\n",
    "        \"electronic, music\",\n",
    "        \"electronic, music, dance, rock, electronica\",\n",
    "'electronic,music,hip-hop / rap, rap',\n",
    "\n",
    "    ],\n",
    "    \"folk\": [\n",
    "        \"folk, rock\"\n",
    "    ],\n",
    "    \"gangsta & hardcore\": [\n",
    "        \"gangsta & hardcore, rap & hip-hop\"\n",
    "    ],\n",
    "    \"gospel\": [\n",
    "        \"gospel, christian\"\n",
    "    ],\n",
    "    \"holiday\": [\n",
    "        \"holiday, christmas, miscellaneous\"\n",
    "    ],\n",
    "    \"international\": [\n",
    "        \"international\",\n",
    "        \"international, latin music\",\n",
    "        \"international, latin music, latin hip-hop\"\n",
    "    ],\n",
    "    \"miscellaneous\": [\n",
    "        \"miscellaneous\",\n",
    "        'house, music, dance, rock, electronic',\n",
    "\n",
    "    ],\n",
    "    \"pop\": [\n",
    "        \"pop\",\n",
    "        \"r&b, pop\",\n",
    "        \"pop, music, electronic, r&b / soul, pop/rock, dance\",\n",
    "        \"pop, music, r&b / soul, contemporary r&b, hip-hop/rap, pop/rock, rock\",\n",
    "        \"pop, music, r&b / soul, dance, teen pop, rock\",\n",
    "        \"pop, music, r&b / soul, rock, dance, contemporary r&b\",\n",
    "        \"pop, music, r&b / soul, teen pop, dance, rock\",\n",
    "        \"pop, music, r&b / soul, soul, dance, rock, jazz, hip-hop / rap, electronic, hip-hop, pop/rock, adult alternative\",\n",
    "        \"pop, music, rock\",\n",
    "        \"pop, music, rock, pop/rock, teen pop, dance\",\n",
    "        \"pop, music, rock, r&b / soul, contemporary r&b, dance\",\n",
    "        \"pop, music, rock, r&b / soul, contemporary r&b, dance, electronic, hip-hop / rap, pop/rock\",\n",
    "        \"pop, music, rock, singer/songwriter, contemporary singer/songwriter, adult alternative\",\n",
    "        \"pop, music, r&b / soul, soul, dance, rock, jazz, hip-hop / rap, electronic, hip-hop, pop/rock, adult alternative\",\n",
    "        'pop, music',\n",
    "'pop, music, r&b / soul,soul,dance,rock,jazz,hip-hop / rap,electronic,hip-hop, pop/rock, adult alternative',\n",
    "'pop, music, rock, r&b / soul, contemporary r&b, dance,electronic,hip-hop / rap, pop/rock',\n",
    "    ],\n",
    "    \"r&b\": [\n",
    "        \"r&b\"\n",
    "    ],\n",
    "    \"rap & hip-hop\": [\n",
    "        \"rap & hip-hop\",\n",
    "        \"rap & hip-hop, southern rap, pop rap\",\n",
    "        \"rap & hip-hop, west coast\",\n",
    "        \"hip-hop/rap, music\",\n",
    "        \"hip-hop/rap, music, dirty south\",\n",
    "        \"hip-hop/rap, music, east coast rap, hardcore rap, rap\",\n",
    "        \"hip-hop/rap, music, hardcore rap, east coast rap, rap\",\n",
    "        \"hip-hop/rap, music, pop, dirty south\",\n",
    "        \"hip-hop/rap, music, r&b / soul, contemporary r&b, dance, rap\",\n",
    "        \"hip-hop/rap, music, rap\",\n",
    "        \"hip-hop/rap, music, rap, dirty south\",\n",
    "        \"hip-hop/rap, music, rap, east coast rap, hardcore rap\",\n",
    "        \"hip-hop/rap, music, rap, electronic, world, dance\",\n",
    "        \"hip-hop/rap, music, rap, hardcore rap, east coast rap, rock\",\n",
    "        \"hip-hop/rap, music, rock, gangsta rap, west coast rap\",\n",
    "        \"dance, music, hip-hop / rap, alternative rap, hip-hop, r&b / soul, soul, electronic\",\n",
    "        \"dance, music, hip-hop / rap, dirty south, rap, electronic\"\n",
    "    ],\n",
    "    \"rock\": [\n",
    "        \"rock\",\n",
    "        \"rock, music, hard rock, alternative\",\n",
    "        \"rock, music, metal, alternative, hard rock\",\n",
    "        \"singer/songwriter, music, rock\",\n",
    "        'rock, music'\n",
    "    ],\n",
    "    \"soundtracks\": [\n",
    "        \"soundtracks\",\n",
    "        \"soundtrack, music, soundtrack, classical, original score\",\n",
    "        \"soundtrack, music, hip-hop / rap, west coast rap, gangsta rap, hardcore rap, rap, soundtrack\",\n",
    "        'soundtrack,music,hip-hop / rap, west coast rap, gangsta rap, hardcore rap, rap, soundtrack'\n",
    "\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "price_hierarchy = {\n",
    "    \"tier one\": [\n",
    "        '$ 0.69',\n",
    "        '$ 0.89'\n",
    "    ],\n",
    "    \"tier two\": [\n",
    "        \"$ 0.99\",'$ 1.29','$ 1.99'\n",
    "    ],}\n",
    "\n",
    "\n",
    "def make_mask(df,frac):\n",
    "    L = len(COL)*len(df)\n",
    "    L_disturb = int(np.ceil(L*frac))\n",
    "    disturb_mask = np.zeros((len(df),len(COL)))\n",
    "    total_elements = disturb_mask.size\n",
    "    random_indices = np.random.choice(total_elements, L_disturb, replace=False)\n",
    "    disturb_mask.flat[random_indices] = 1\n",
    "    return disturb_mask \n",
    "\n",
    "\n",
    "def find_parents(hierarchy, target, parents=None):\n",
    "    if parents is None:\n",
    "        parents = []\n",
    "\n",
    "    for key, value in hierarchy.items():\n",
    "        if key == target:  # If the target itself is a key\n",
    "            return parents + [key]\n",
    "        if isinstance(value, dict):  # If value is a nested dictionary\n",
    "            result = find_parents(value, target, parents + [key])\n",
    "            if result != -1:\n",
    "                return result\n",
    "        elif isinstance(value, list) and target in value:  # If value is a list containing the target\n",
    "            return parents + [key]\n",
    "\n",
    "    return -1  # Return -1 if the target is not found\n",
    "\n",
    "\n",
    "def convert_to_seconds(time_str):\n",
    "    minutes, seconds = map(int, time_str.split(':'))\n",
    "    return minutes * 60 + seconds\n",
    "\n",
    "\n",
    "def disturb_func(col,value):\n",
    "    if col =='Price':\n",
    "        if value == 'Album Only':\n",
    "            new_velue = 'other'\n",
    "        else:\n",
    "            parents = find_parents(price_hierarchy, value)\n",
    "            if parents == -1: print(value)\n",
    "            new_seed = int(time.time())\n",
    "            np.random.seed(new_seed)\n",
    "            np.random.shuffle(parents)\n",
    "            new_velue = parents[0]\n",
    "        \n",
    "\n",
    "    elif col == 'Genre':\n",
    "        parents = find_parents(genre_hierarchy,value.lower().replace(' , ',', '))\n",
    "        if parents == -1: print(value)\n",
    "        new_seed = int(time.time())\n",
    "        np.random.seed(new_seed)\n",
    "        np.random.shuffle(parents)\n",
    "        new_velue = parents[0]\n",
    "\n",
    "\n",
    "    elif col == 'Released':\n",
    "        # print(value)\n",
    "\n",
    "\n",
    "\n",
    "        if str(value) =='nan':\n",
    "            new_velue = 'other'            \n",
    "\n",
    "        elif '-' in value:\n",
    "            value = value.split('-')\n",
    "            \n",
    "            if len(value[0]) ==1:\n",
    "                value[0] = '0'+str(value[0])\n",
    "\n",
    "            if int(value[2]) > 20:\n",
    "                yy = '19'+str(value[2])\n",
    "            else:\n",
    "                yy = '20'+str(value[2])\n",
    "                tr_dict = {'Jan':'January',\n",
    "                        'Feb':'February',\n",
    "                        'Mar':'March',\n",
    "                        'Apr':'April',\n",
    "                        'May':'May',\n",
    "                        'Jun':'June',\n",
    "                        'Jul':'July',\n",
    "                        'Aug':'August',\n",
    "                        'Sep':'September',\n",
    "                        'Oct':'October',\n",
    "                        'Nov':'November',\n",
    "                        'Dec':'December'}\n",
    "\n",
    "            value =  yy + '/'   + tr_dict[value[1]]+'/'+ value[0]\n",
    "            parents = find_parents(date_hierarchy, value)\n",
    "\n",
    "        elif ',' in value:\n",
    "            value = value.replace(', ','').split(' ')\n",
    "            \n",
    "            if len(value[1]) ==1:\n",
    "                value[1] = '0'+value[1]\n",
    "\n",
    "                    \n",
    "            value= value[2]+'/'+value[0]+'/'+value[1]\n",
    "            parents = find_parents(date_hierarchy, value)\n",
    "\n",
    "        else:\n",
    "            parents = find_parents(date_hierarchy, value)\n",
    "        if str(value) !='nan':\n",
    "            # print(parents,value)\n",
    "            new_seed = int(time.time())\n",
    "            np.random.seed(new_seed)\n",
    "            np.random.shuffle(parents)\n",
    "            new_velue = parents[0]\n",
    "\n",
    "    elif col =='Time':\n",
    "        if str(value) =='nan':\n",
    "            new_velue = 'other'\n",
    "\n",
    "        else:\n",
    "\n",
    "            data_in_seconds = [convert_to_seconds(length) for length in [value]]\n",
    "            music_hierarchy = {\n",
    "                \"Short\": {\n",
    "                    \"Very Short\": [n for n in data_in_seconds if n < 60],\n",
    "                    \"Short high\": [n for n in data_in_seconds if 60 <= n < 180]\n",
    "                },\n",
    "                \"Moderate\": {\n",
    "                    \"Moderate Low\": [n for n in data_in_seconds if 180 <= n < 300],\n",
    "                    \"Moderate High\": [n for n in data_in_seconds if 300 <= n < 480]\n",
    "                },\n",
    "                \"Long\": {\n",
    "                    \"Long Low\": [n for n in data_in_seconds if 480 <= n < 600],\n",
    "                    \"Long High\": [n for n in data_in_seconds if 600 <= n < 900]\n",
    "                },\n",
    "                \"Very Long\": {\n",
    "                    \"Very Long Low\": [n for n in data_in_seconds if 900 <= n < 1200],\n",
    "                    \"Very Long High\": [n for n in data_in_seconds if n >= 1200]\n",
    "                }\n",
    "            }\n",
    "            parents = find_parents(music_hierarchy, data_in_seconds[0])\n",
    "            if parents == -1:\n",
    "                print(value,'time')\n",
    "            new_seed = int(time.time())\n",
    "            np.random.seed(new_seed)\n",
    "            np.random.shuffle(parents)\n",
    "            new_velue = parents[0]\n",
    "        \n",
    "    return new_velue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "task = 'iTunes-Amazon'\n",
    "COL = ['Genre', 'Price', 'Time','Released']\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "for frac in [0,0.1,0.2,0.3,0.4,0.5,0.7,0.9]:\n",
    "    L =[]\n",
    "    for rep in range(1,101):\n",
    "        df = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/data/\" + task  +'/test.csv')\n",
    "\n",
    "        mask_left = make_mask(df,frac)\n",
    "        mask_right = make_mask(df,frac)\n",
    "        x = 0\n",
    "\n",
    "        for i,col in enumerate(COL):\n",
    "            df.loc[mask_left[:,i] == 1, 'left_'+col] = df.loc[mask_left[:,i] == 1, 'left_'+col].apply(lambda x: disturb_func(col, x))\n",
    "            df.loc[mask_right[:,i] == 1, 'right_'+col] = df.loc[mask_right[:,i] == 1, 'right_'+col].apply(lambda x: disturb_func(col, x))\n",
    "\n",
    "            x+=(column_entropy(df['left_'+col]) +column_entropy(df['right_'+col]))\n",
    "\n",
    "        L.append(x)\n",
    "    if frac ==0:\n",
    "        base = np.average(L).copy()\n",
    "    base =1\n",
    "    print(round(np.average(L)/base,2), round(np.sqrt(np.std(L))/base,2))\n",
    "\n",
    "print('itun')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
