{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/Walmart-Amazon/train.csv')\n",
    "tmp1 = list(np.unique(list(df['left_modelno'])))\n",
    "tmp2 = list(np.unique(list(df['right_modelno'])))\n",
    "\n",
    "df = pd.read_csv('data/Walmart-Amazon/valid.csv')\n",
    "tmp3 = list(np.unique(list(df['left_modelno'])))\n",
    "tmp4 = list(np.unique(list(df['right_modelno'])))\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/Walmart-Amazon/test.csv')\n",
    "tmp5 = list(np.unique(list(df['left_modelno'])))\n",
    "tmp6 = list(np.unique(list(df['right_modelno'])))\n",
    "\n",
    "\n",
    "tmp = tmp1+ tmp2+ tmp3+ tmp4+ tmp5+ tmp6\n",
    "\n",
    "\n",
    "tmp = list(np.unique(tmp))\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def create_hierarchy(identifiers):\n",
    "    def nested_dict():\n",
    "        return defaultdict(nested_dict)\n",
    "\n",
    "    hierarchy = nested_dict()\n",
    "\n",
    "    for identifier in identifiers:\n",
    "        if re.match(r'^\\d', identifier):  # Numerical identifiers\n",
    "            prefix = re.match(r'^\\d+', identifier).group()  # Extract leading digits\n",
    "            sub_prefix = identifier[len(prefix):len(prefix) + 2]  # Next two characters after the prefix\n",
    "            hierarchy['Numerical Prefixes'][prefix][sub_prefix][identifier] = {}\n",
    "        elif re.match(r'^[a-zA-Z]', identifier):  # Alphanumeric identifiers\n",
    "            first_char = identifier[0].lower()  # First character\n",
    "            sub_prefix = re.match(r'^[a-zA-Z0-9]+', identifier).group()[:3]  # First three characters\n",
    "            hierarchy['Alphanumeric Identifiers'][first_char][sub_prefix][identifier] = {}\n",
    "        elif '-' in identifier:  # Hyphenated identifiers\n",
    "            prefix = identifier.split('-')[0]  # Segment before first hyphen\n",
    "            sub_prefix = identifier.split('-')[1] if len(identifier.split('-')) > 1 else \"Misc\"\n",
    "            hierarchy['Hyphenated Identifiers'][prefix][sub_prefix][identifier] = {}\n",
    "        elif '.' in identifier or 'e' in identifier:  # Dot-separated or scientific notation\n",
    "            prefix = 'Sci-Notation' if 'e' in identifier else 'Dot-Separated'\n",
    "            sub_prefix = identifier.split('.')[0]  # Segment before the first dot\n",
    "            hierarchy['Dot-Separated Identifiers'][prefix][sub_prefix][identifier] = {}\n",
    "        else:  # Special characters or miscellaneous\n",
    "            prefix = identifier[0] if identifier[0].isalpha() else \"Misc\"\n",
    "            hierarchy['Special Characters'][prefix][identifier] = {}\n",
    "\n",
    "    def convert_to_dict(d):\n",
    "        \"\"\"Helper function to convert defaultdict to a regular dict.\"\"\"\n",
    "        if isinstance(d, defaultdict):\n",
    "            return {k: convert_to_dict(v) for k, v in d.items()}\n",
    "        return d\n",
    "\n",
    "    return convert_to_dict(hierarchy)\n",
    "\n",
    "hierarchy_dict = create_hierarchy(tmp)\n",
    "# print_hierarchy(hierarchy)\n",
    "\n",
    "hierarchy_dict\n",
    "\n",
    "find_parents(hierarchy_dict,'000mio5000m')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# with open('walmartmodelno.json', \"r\", encoding=\"utf-8\") as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "file_name = \"walmartmodelno.json\"\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(hierarchy_dict, json_file, indent=4)  # 'indent=4' for pretty formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def print_hierarchy(d, indent=0):\n",
    "    for key, value in d.items():\n",
    "        print(\" \" * indent + f\"- {key}\")\n",
    "        if isinstance(value, dict):\n",
    "            print_hierarchy(value, indent + 4)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                print(\" \" * (indent + 4) + f\"- {item}\")\n",
    "\n",
    "# Print the hierarchy\n",
    "\n",
    "df= pd.read_csv('tmp.csv')\n",
    "y_true, y_score = df.iloc[:, 1], df.iloc[:, 0]\n",
    "\n",
    "auc_ = roc_auc_score(y_true, y_score)\n",
    "auc_\n",
    "\n",
    "# 0.9980947196516059\n",
    "# 0.997005988023952\n",
    "# 0.987751769188895\n",
    "# 0.9648884050081655\n",
    "# 0.9918345127925966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "MEAN = 10000\n",
    "MAXX = -1\n",
    "# for task in ['iTunes-Amazon','Fodors-Zagats','Walmart-Amazon']:\n",
    "for task in ['Fodors-Zagats']:\n",
    "    plt.figure(figsize=(25, 16.5))  # (19,13.5)\n",
    "    plt.xlabel('Rate', fontsize=60)\n",
    "    plt.ylabel('AUC', fontsize=60)\n",
    "    plt.yticks(fontsize=50)\n",
    "    # if task == 'Fodors-Zagats':\n",
    "    #     plt.xticks([0, 0.1, .2, .3, .40, .50, ], ['0\\n27.0±0.0', '10\\n27.8±0.4', '20\\n27.7±0.4', '30\\n27.1±0.5', '40\\n26.3±0.5', '50\\n25.3±0.5'], fontsize=35)\n",
    "    # if task == 'Walmart-Amazon':\n",
    "    #     plt.xticks([0, 0.1, .2, .3, .40, .50, ], ['0\\n39.2±0.0', '10\\n39.2±0.5', '20\\n38.0±0.8', '30\\n36.2±0.7', '40\\n35.0±0.7', '50\\n32.7±1.01'], fontsize=35)\n",
    "    # if task == 'iTunes-Amazon':\n",
    "    #     plt.xticks([0, 0.1, .2, .3, .40, .50, ], ['0\\n32.8±0.0', '10\\n33.9±0.4', '20\\n33.8±0.1', '30\\n32.5±0.8', '40\\n29.8±0.1', '50\\n28.5±0.36'], fontsize=35)\n",
    "\n",
    "    # plt.xticks([0, 0.1, .2, .3, .40, .50, ], ['0', '10', '20', '30', '40', '50'], fontsize=50)\n",
    "    plt.xticks([0, 0.1, .2, .3, .40, .50, 0.7,0.9], ['0', '10', '20', '30', '40', '50','70','90'], fontsize=50)\n",
    "\n",
    "\n",
    "    # List of model names\n",
    "    model_names_base = ['Hiermatcher', 'DeepMatcher', 'DITTO', 'EMTransformer', 'HierGAT']\n",
    "    model_names_base = [ 'DeepMatcher', 'DITTO', 'EMTransformer', 'HierGAT']\n",
    "    model_names_base = [ 'DITTO','DeepMatcher','EMTransformer','HierGAT']\n",
    "    model_names_base = [ 'DITTO','DeepMatcher','EMTransformer','HierGAT']\n",
    "    model_names_base = [ 'DeepMatcher','DITTO','HierGAT','EMTransformer']\n",
    "    model_names_base = [ 'DeepMatcher']\n",
    "    # model_names_base = [ 'DeepMatcher','EMTransformer','HierGAT']\n",
    "    model_names = [] \n",
    "    for row in model_names_base:\n",
    "        model_names.append(row + task)\n",
    "\n",
    "    # Mapping model names to abbreviations\n",
    "    name_to_abbreviation = {\n",
    "        # 'Hiermatcher': 'HM',\n",
    "        'DeepMatcher': 'DM',\n",
    "        'DITTO': 'DITTO',\n",
    "        'EMTransformer': 'EM',\n",
    "        'HierGAT': 'HG'\n",
    "    }\n",
    "\n",
    "    # Dictionary for colors and markers\n",
    "    style_dict = {\n",
    "        # 'Hiermatcher': {'color': '#377eb8', 'marker': '^'},\n",
    "        'DeepMatcher': {'color': '#F4D35E', 'marker': 'o'},\n",
    "        'DITTO': {'color': '#E07A5F', 'marker': '*'},\n",
    "        'EMTransformer': {'color': '#5DADEC', 'marker': 's'},\n",
    "        'HierGAT': {'color': '#88C070', 'marker': 'v'}\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Green: #88C070\n",
    "# Red: #E07A5F\n",
    "# Blue: #5DADEC\n",
    "# Yellow: #F4D35E\n",
    "    # Fracture rates and folds\n",
    "    frac_values = ['00','10','20','30','40','50']\n",
    "    frac_values = ['00','10','20','30','40','50','70','90']\n",
    "    # frac_values = frac_values[1:-7]\n",
    "    # folds = range(1, 3)\n",
    "\n",
    "    for name in model_names:\n",
    "        if name == 'Hiermatcher_company': continue\n",
    "        AUC = []\n",
    "\n",
    "        for frac in frac_values:\n",
    "            auc_list = []\n",
    "            \n",
    "            # for rep in range(1, 11):\n",
    "            if 'Deep' in name: \n",
    "                R = range(1,4)\n",
    "            else:\n",
    "                R = range(1,6)\n",
    "            \n",
    "            R = range(1,17)\n",
    "\n",
    "            if frac =='00':\n",
    "                R = [1]\n",
    "            if frac in ['10','20']:\n",
    "                R = range(1,4)\n",
    "            # if frac in ['90']:\n",
    "            #     R = range(1,9)\n",
    "            # if frac in ['70']:\n",
    "            #     R = range(1,11)\n",
    "\n",
    "            for rep in R:\n",
    "                tmp = name_to_abbreviation.get(name.replace(task,''), name.replace(task,''))\n",
    "                file_path = f'out_score_hier_train/{name}2/{tmp}_score_'+task+f'_{frac}_{rep}.csv'\n",
    "                \n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                y_true, y_score = df.iloc[:, 1], df.iloc[:, 0]\n",
    "                if 'HierGAT' in name:\n",
    "                    y_true, y_score = df.iloc[:, 0], df.iloc[:, 1]\n",
    "\n",
    "                y_score2  = [1 if r > 0.8 else 0 for r in y_score]\n",
    "\n",
    "                auc_ = roc_auc_score(y_true, y_score)\n",
    "                auc_list.append(auc_)\n",
    "\n",
    "            AUC.append(auc_list)\n",
    "\n",
    "        \n",
    "        \n",
    "        # AUC[0]= AUC[0]+AUC[0]+AUC[0]+AUC[0]+AUC[0]+AUC[0]+AUC[0]+AUC[0]+AUC[0]+AUC[0]+AUC[0]+AUC[0]+AUC[0]+AUC[0]+AUC[0]+AUC[0]\n",
    "        # AUC[1]= AUC[1]+AUC[1]+AUC[1]+AUC[1]+AUC[1]+AUC[1][0:1]\n",
    "        # AUC[2]= AUC[2]+AUC[2]+AUC[2]+AUC[2]+AUC[2]+AUC[2][0:1]\n",
    "        \n",
    "        # AUC[-1]= AUC[-1]+AUC[-1]\n",
    "        # AUC[-2]= AUC[-2]+AUC[-2][0:6\n",
    "        #                          ]\n",
    "\n",
    "        # AUC[0]= AUC[0]+AUC[0]+AUC[0]\n",
    "        # AUC = np.array(AUC)\n",
    "        mean_auc,std_aud =  make_auc_ready(AUC)\n",
    "        # mean_auc = np.mean(AUC, axis=1)\n",
    "        MEAN = min(np.min(mean_auc), MEAN)\n",
    "        MAXX = max(np.max(mean_auc), MAXX)\n",
    "\n",
    "        # Plot with error bars\n",
    "        frac_float = [x / 100 for x in range(0, 101, 10)]\n",
    "        frac_float = [x / 100 for x in range(0, 51, 10)]\n",
    "        frac_float = [0,0.1,0.2,0.3,0.4,0.5,0.7,0.9]\n",
    "        # frac_float = [0,0.1,0.2,0.3,0.4,0.5]\n",
    "\n",
    "            \n",
    "        plt.plot(frac_float, mean_auc, 'b-',marker=style_dict[name.replace(task,'')]['marker'],markerfacecolor=style_dict[name.replace(task,'')]['color'],color=style_dict[name.replace(task,'')]['color'],\n",
    "                 markeredgecolor='black',\n",
    "                    markersize=27, linewidth=7, \n",
    "                    label=name_to_abbreviation[name.replace(task,'')].replace('HG','HierGAT').replace('EM','EMTrans').replace('DM','DeepMatch'))\n",
    "        \n",
    "        from scipy import stats\n",
    "        confidence_interval = 0.95\n",
    "        z_score = stats.norm.ppf((1 + confidence_interval) / 2)\n",
    "        margin_of_error = z_score * (np.sqrt(std_aud) / ((5)))\n",
    "\n",
    "        plt.fill_between(frac_float,\n",
    "                        mean_auc - margin_of_error,\n",
    "                        mean_auc + margin_of_error,\n",
    "                        alpha=0.25,color=style_dict[name.replace(task,'')]['color'])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # plt.savefig(task+'_hierarch'+'.pdf')\n",
    "    # plt.savefig('fodor_hierarch_emt'+'.pdf')\n",
    "    # # # # Show the plot\n",
    "    # plt.close()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "MEAN = 10000\n",
    "MAXX = -1\n",
    "# for task in ['iTunes-Amazon','Fodors-Zagats','Walmart-Amazon']:\n",
    "for task in ['Fodors-Zagats']:\n",
    "    \n",
    "\n",
    "    # List of model names\n",
    "    model_names_base = ['Hiermatcher', 'DeepMatcher', 'DITTO', 'EMTransformer', 'HierGAT']\n",
    "    model_names_base = [ 'DeepMatcher', 'DITTO', 'EMTransformer', 'HierGAT']\n",
    "    model_names_base = [ 'DITTO','DeepMatcher','EMTransformer','HierGAT']\n",
    "    model_names_base = [ 'DITTO','DeepMatcher','EMTransformer','HierGAT']\n",
    "    model_names_base = [ 'DITTO','HierGAT','EMTransformer']\n",
    "    # model_names_base = [ 'DeepMatcher','EMTransformer','HierGAT']\n",
    "    model_names = [] \n",
    "    for row in model_names_base:\n",
    "        model_names.append(row + task)\n",
    "\n",
    "    # Mapping model names to abbreviations\n",
    "    name_to_abbreviation = {\n",
    "        # 'Hiermatcher': 'HM',\n",
    "        'DeepMatcher': 'DM',\n",
    "        'DITTO': 'DITTO',\n",
    "        'EMTransformer': 'EM',\n",
    "        'HierGAT': 'HG'\n",
    "    }\n",
    "\n",
    "    # Dictionary for colors and markers\n",
    "    style_dict = {\n",
    "        # 'Hiermatcher': {'color': '#377eb8', 'marker': '^'},\n",
    "        'DeepMatcher': {'color': '#F4D35E', 'marker': 'o'},\n",
    "        'DITTO': {'color': '#E07A5F', 'marker': '*'},\n",
    "        'EMTransformer': {'color': '#5DADEC', 'marker': 's'},\n",
    "        'HierGAT': {'color': '#88C070', 'marker': 'v'}\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    frac_values = ['00','10','20','30','40','50']\n",
    "    for name in model_names:\n",
    "        frac_values = ['00','10','20','30','40','50','70','90']\n",
    "\n",
    "\n",
    "\n",
    "        if name == 'Hiermatcher_company': continue\n",
    "        AUC = []\n",
    "\n",
    "        for frac in frac_values:\n",
    "            auc_list = []\n",
    "            \n",
    "\n",
    "            R = range(1,6)\n",
    "            if 'EMT' in name or 'GAT' in name:\n",
    "                if frac in ['70','90']:\n",
    "                    R= [1,2]\n",
    "            if frac =='00':\n",
    "                R = [1]\n",
    "\n",
    "\n",
    "            for rep in R:\n",
    "                tmp = name_to_abbreviation.get(name.replace(task,''), name.replace(task,''))\n",
    "                file_path = f'out_score_hier_train/{name}/{tmp}_score_'+task+f'_{frac}_{rep}.csv'\n",
    "                # print(file_path)\n",
    "                \n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                y_true, y_score = df.iloc[:, 1], df.iloc[:, 0]\n",
    "                if 'HierGAT' in name:\n",
    "                    y_true, y_score = df.iloc[:, 0], df.iloc[:, 1]\n",
    "\n",
    "                y_score2  = [1 if r > 0.8 else 0 for r in y_score]\n",
    "\n",
    "                auc_ = roc_auc_score(y_true, y_score)\n",
    "                auc_list.append(auc_)\n",
    "\n",
    "            AUC.append(auc_list)\n",
    "\n",
    "        mean_auc,std_aud =  make_auc_ready(AUC)\n",
    "        MEAN = min(np.min(mean_auc), MEAN)\n",
    "        MAXX = max(np.max(mean_auc), MAXX)\n",
    "\n",
    "        # Plot with error bars\n",
    "        frac_float = [x / 100 for x in range(0, 101, 10)]\n",
    "        frac_float = [x / 100 for x in range(0, 51, 10)]\n",
    "        frac_float = [0,0.1,0.2,0.3,0.4,0.5,0.7,0.9]\n",
    "\n",
    "\n",
    "            \n",
    "        plt.plot(frac_float, mean_auc, 'b-',marker=style_dict[name.replace(task,'')]['marker'],markerfacecolor=style_dict[name.replace(task,'')]['color'],color=style_dict[name.replace(task,'')]['color'],\n",
    "                 markeredgecolor='black',\n",
    "                    markersize=27, linewidth=7, \n",
    "                    label=name_to_abbreviation[name.replace(task,'')].replace('HG','HierGAT').replace('EM','EMTrans').replace('DM','DeepMatch'))\n",
    "        \n",
    "        from scipy import stats\n",
    "        confidence_interval = 0.95\n",
    "        z_score = stats.norm.ppf((1 + confidence_interval) / 2)\n",
    "        margin_of_error = z_score * (np.sqrt(std_aud) / ((5)))\n",
    "\n",
    "        plt.fill_between(frac_float,\n",
    "                        mean_auc - margin_of_error,\n",
    "                        mean_auc + margin_of_error,\n",
    "                        alpha=0.25,color=style_dict[name.replace(task,'')]['color'])\n",
    "\n",
    "    \n",
    "# plt.legend(fontsize=50, loc = 'lower left',bbox_to_anchor = (-0.017,-0.017))\n",
    "# Formatter function for y-axis\n",
    "def format_y(value, tick_number): return f'{value:.3f}'\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(format_y))\n",
    "plt.tick_params(axis='both', which='major', length=10, width=2)\n",
    "plt.tick_params(axis='both', which='minor', length=5, width=1)\n",
    "if 'Fodor' in task:\n",
    "    plt.legend(fontsize=45, loc = 'lower left',bbox_to_anchor = (-0.017,-0.017))\n",
    "plt.grid()    \n",
    "# plt.ylim([0.95,1.005])\n",
    "tmp = plt.gca().get_xlim()\n",
    "top_axis = plt.twiny()\n",
    "top_axis.set_xlim(tmp)  # Match the limits of the bottom axis\n",
    "# top_axis.set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5])  \n",
    "top_axis.set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5,0.7,0.9])  \n",
    "\n",
    "\n",
    "# plt.twiny()\n",
    "if task == 'Fodors-Zagats':\n",
    "    plt.xticks([0, 0.1, .2, .3, .40, .50,0.7,0.9 ], ['27.0\\n±0.0', '27.8\\n±0.4', '27.7\\n±0.4', '27.1\\n±0.5', '26.3\\n±0.5', '25.3\\n±0.5','22.4\\n±0.5','18.5\\n±0.4'], fontsize=45)\n",
    "if task == 'Walmart-Amazon':\n",
    "    plt.xticks([0, 0.1, .2, .3, .40, .50, ], ['39.2\\n±0.0', '39.2\\n±0.5', '38.0\\n±0.8', '36.2\\n±0.7', '35.0\\n±0.7', '32.7\\n±1.01'], fontsize=45)\n",
    "if task == 'iTunes-Amazon':\n",
    "    plt.xticks([0, 0.1, .2, .3, .40, .50, ], ['32.8\\n±0.0', '33.9\\n±0.4', '33.8\\n±0.1', '32.5\\n±0.8', '29.8\\n±0.1', '28.5\\n±0.36'], fontsize=45)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Average Data Entropy \\n± variance\\n', fontsize=50)\n",
    "plt.tick_params(axis='both', which='major', length=10, width=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig('Fodors-Zagats_hierarch_train.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "MEAN = 10000\n",
    "MAXX = -1\n",
    "# for task in ['iTunes-Amazon','Fodors-Zagats','Walmart-Amazon']:\n",
    "for task in ['iTunes-Amazon']:\n",
    "    plt.figure(figsize=(25, 16.5))  # (19,13.5)\n",
    "    plt.xlabel('Rate', fontsize=60)\n",
    "    plt.ylabel('AUC', fontsize=60)\n",
    "    plt.yticks(fontsize=50)\n",
    "    # if task == 'Fodors-Zagats':\n",
    "    #     plt.xticks([0, 0.1, .2, .3, .40, .50, ], ['0\\n27.0±0.0', '10\\n27.8±0.4', '20\\n27.7±0.4', '30\\n27.1±0.5', '40\\n26.3±0.5', '50\\n25.3±0.5'], fontsize=35)\n",
    "    # if task == 'Walmart-Amazon':\n",
    "    #     plt.xticks([0, 0.1, .2, .3, .40, .50, ], ['0\\n39.2±0.0', '10\\n39.2±0.5', '20\\n38.0±0.8', '30\\n36.2±0.7', '40\\n35.0±0.7', '50\\n32.7±1.01'], fontsize=35)\n",
    "    # if task == 'iTunes-Amazon':\n",
    "    #     plt.xticks([0, 0.1, .2, .3, .40, .50, ], ['0\\n32.8±0.0', '10\\n33.9±0.4', '20\\n33.8±0.1', '30\\n32.5±0.8', '40\\n29.8±0.1', '50\\n28.5±0.36'], fontsize=35)\n",
    "\n",
    "    # plt.xticks([0, 0.1, .2, .3, .40, .50, ], ['0', '10', '20', '30', '40', '50'], fontsize=50)\n",
    "    plt.xticks([0, 0.1, .2, .3, .40, .50, 0.7,0.9], ['0', '10', '20', '30', '40', '50','70','90'], fontsize=50)\n",
    "\n",
    "\n",
    "    # List of model names\n",
    "    model_names_base = ['Hiermatcher', 'DeepMatcher', 'DITTO', 'EMTransformer', 'HierGAT']\n",
    "    model_names_base = [ 'DeepMatcher', 'DITTO', 'EMTransformer', 'HierGAT']\n",
    "    model_names_base = [ 'DITTO','DeepMatcher','EMTransformer','HierGAT']\n",
    "    model_names_base = [ 'DITTO','DeepMatcher','EMTransformer','HierGAT']\n",
    "    model_names_base = [ 'DeepMatcher','DITTO','HierGAT','EMTransformer']\n",
    "    model_names_base = [ 'DeepMatcher']\n",
    "    # model_names_base = [ 'DeepMatcher','EMTransformer','HierGAT']\n",
    "    model_names = [] \n",
    "    for row in model_names_base:\n",
    "        model_names.append(row + task)\n",
    "\n",
    "    # Mapping model names to abbreviations\n",
    "    name_to_abbreviation = {\n",
    "        # 'Hiermatcher': 'HM',\n",
    "        'DeepMatcher': 'DM',\n",
    "        'DITTO': 'DITTO',\n",
    "        'EMTransformer': 'EM',\n",
    "        'HierGAT': 'HG'\n",
    "    }\n",
    "\n",
    "    # Dictionary for colors and markers\n",
    "    style_dict = {\n",
    "        # 'Hiermatcher': {'color': '#377eb8', 'marker': '^'},\n",
    "        'DeepMatcher': {'color': '#F4D35E', 'marker': 'o'},\n",
    "        'DITTO': {'color': '#E07A5F', 'marker': '*'},\n",
    "        'EMTransformer': {'color': '#5DADEC', 'marker': 's'},\n",
    "        'HierGAT': {'color': '#88C070', 'marker': 'v'}\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Green: #88C070\n",
    "# Red: #E07A5F\n",
    "# Blue: #5DADEC\n",
    "# Yellow: #F4D35E\n",
    "    # Fracture rates and folds\n",
    "    frac_values = ['00','10','20','30','40','50','70','90']\n",
    "    # frac_values = frac_values[1:-7]\n",
    "    # folds = range(1, 3)\n",
    "\n",
    "    for name in model_names:\n",
    "        if name == 'Hiermatcher_company': continue\n",
    "        AUC = []\n",
    "\n",
    "        for frac in frac_values:\n",
    "            auc_list = []\n",
    "            \n",
    "\n",
    "            \n",
    "            R = range(1,4)\n",
    "\n",
    "            if frac =='00':\n",
    "                R = [1]\n",
    "            # if frac =='70':\n",
    "            #     R = [1,2]\n",
    "\n",
    "\n",
    "            # if frac in ['70','90']:\n",
    "            #     R = [1,2]\n",
    "            # if frac in ['90']:\n",
    "            #     R = range(1,9)\n",
    "            # if frac in ['70']:\n",
    "            #     R = range(1,11)\n",
    "\n",
    "            for rep in R:\n",
    "                tmp = name_to_abbreviation.get(name.replace(task,''), name.replace(task,''))\n",
    "                file_path = f'out_score_hier_train/{name}/{tmp}_score_'+task+f'_{frac}_{rep}.csv'\n",
    "                \n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                y_true, y_score = df.iloc[:, 1], df.iloc[:, 0]\n",
    "                if 'HierGAT' in name:\n",
    "                    y_true, y_score = df.iloc[:, 0], df.iloc[:, 1]\n",
    "\n",
    "                y_score2  = [1 if r > 0.8 else 0 for r in y_score]\n",
    "\n",
    "                auc_ = roc_auc_score(y_true, y_score)\n",
    "                auc_list.append(auc_)\n",
    "\n",
    "            AUC.append(auc_list)\n",
    "\n",
    "#\n",
    "        # AUC = np.array(AUC)\n",
    "        mean_auc,std_aud =  make_auc_ready(AUC)\n",
    "\n",
    "        MEAN = min(np.min(mean_auc), MEAN)\n",
    "        MAXX = max(np.max(mean_auc), MAXX)\n",
    "\n",
    "        # Plot with error bars\n",
    "        frac_float = [x / 100 for x in range(0, 101, 10)]\n",
    "        frac_float = [x / 100 for x in range(0, 51, 10)]\n",
    "        frac_float = [0,0.1,0.2,0.3,0.4,0.5,0.7,0.9]\n",
    "\n",
    "            \n",
    "        plt.plot(frac_float, mean_auc, 'b-',marker=style_dict[name.replace(task,'')]['marker'],markerfacecolor=style_dict[name.replace(task,'')]['color'],color=style_dict[name.replace(task,'')]['color'],\n",
    "                 markeredgecolor='black',\n",
    "                    markersize=27, linewidth=7, \n",
    "                    label=name_to_abbreviation[name.replace(task,'')].replace('HG','HierGAT').replace('EM','EMTrans').replace('DM','DeepMatch'))\n",
    "        \n",
    "        from scipy import stats\n",
    "        confidence_interval = 0.95\n",
    "        z_score = stats.norm.ppf((1 + confidence_interval) / 2)\n",
    "        margin_of_error = z_score * (np.sqrt(std_aud)) / 5\n",
    "\n",
    "        plt.fill_between(frac_float,\n",
    "                        mean_auc - margin_of_error,\n",
    "                        mean_auc + margin_of_error,\n",
    "                        alpha=0.25,color=style_dict[name.replace(task,'')]['color'])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # plt.savefig(task+'_hierarch'+'.pdf')\n",
    "    # plt.savefig('fodor_hierarch_emt'+'.pdf')\n",
    "    # # # # Show the plot\n",
    "    # plt.close()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "MEAN = 10000\n",
    "MAXX = -1\n",
    "# for task in ['iTunes-Amazon','Fodors-Zagats','Walmart-Amazon']:\n",
    "for task in ['iTunes-Amazon']:\n",
    "    \n",
    "\n",
    "    # List of model names\n",
    "    model_names_base = ['Hiermatcher', 'DeepMatcher', 'DITTO', 'EMTransformer', 'HierGAT']\n",
    "    model_names_base = [ 'DeepMatcher', 'DITTO', 'EMTransformer', 'HierGAT']\n",
    "    model_names_base = [ 'DITTO','DeepMatcher','EMTransformer','HierGAT']\n",
    "    model_names_base = [ 'DITTO','DeepMatcher','EMTransformer','HierGAT']\n",
    "    model_names_base = [ 'DITTO','HierGAT','EMTransformer']\n",
    "    # model_names_base = [ 'DeepMatcher','EMTransformer','HierGAT']\n",
    "    model_names = [] \n",
    "    for row in model_names_base:\n",
    "        model_names.append(row + task)\n",
    "\n",
    "    # Mapping model names to abbreviations\n",
    "    name_to_abbreviation = {\n",
    "        # 'Hiermatcher': 'HM',\n",
    "        'DeepMatcher': 'DM',\n",
    "        'DITTO': 'DITTO',\n",
    "        'EMTransformer': 'EM',\n",
    "        'HierGAT': 'HG'\n",
    "    }\n",
    "\n",
    "    # Dictionary for colors and markers\n",
    "    style_dict = {\n",
    "        # 'Hiermatcher': {'color': '#377eb8', 'marker': '^'},\n",
    "        'DeepMatcher': {'color': '#F4D35E', 'marker': 'o'},\n",
    "        'DITTO': {'color': '#E07A5F', 'marker': '*'},\n",
    "        'EMTransformer': {'color': '#5DADEC', 'marker': 's'},\n",
    "        'HierGAT': {'color': '#88C070', 'marker': 'v'}\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    frac_values = ['00','10','20','30','40','50']\n",
    "    for name in model_names:\n",
    "        frac_values = ['00','10','20','30','40','50','70','90']\n",
    "\n",
    "\n",
    "\n",
    "        if name == 'Hiermatcher_company': continue\n",
    "        AUC = []\n",
    "\n",
    "        for frac in frac_values:\n",
    "            auc_list = []\n",
    "            \n",
    "\n",
    "            R = range(1,6)\n",
    "            if frac =='00':\n",
    "                R = [1]\n",
    "            if frac in ['70','90']:\n",
    "                R=[1,2]\n",
    "\n",
    "\n",
    "            for rep in R:\n",
    "                tmp = name_to_abbreviation.get(name.replace(task,''), name.replace(task,''))\n",
    "                file_path = f'out_score_hier_train/{name}/{tmp}_score_'+task+f'_{frac}_{rep}.csv'\n",
    "                # print(file_path)\n",
    "                \n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                y_true, y_score = df.iloc[:, 1], df.iloc[:, 0]\n",
    "                if 'HierGAT' in name:\n",
    "                    y_true, y_score = df.iloc[:, 0], df.iloc[:, 1]\n",
    "\n",
    "                y_score2  = [1 if r > 0.8 else 0 for r in y_score]\n",
    "\n",
    "                auc_ = roc_auc_score(y_true, y_score)\n",
    "                auc_list.append(auc_)\n",
    "\n",
    "            AUC.append(list(auc_list))\n",
    "\n",
    "\n",
    "        mean_auc,std_aud =  make_auc_ready(AUC)\n",
    "        frac_float = [0,0.1,0.2,0.3,0.4,0.5,0.7,0.9]\n",
    "\n",
    "\n",
    "            \n",
    "        plt.plot(frac_float, mean_auc, 'b-',marker=style_dict[name.replace(task,'')]['marker'],markerfacecolor=style_dict[name.replace(task,'')]['color'],color=style_dict[name.replace(task,'')]['color'],\n",
    "                 markeredgecolor='black',\n",
    "                    markersize=27, linewidth=7, \n",
    "                    label=name_to_abbreviation[name.replace(task,'')].replace('HG','HierGAT').replace('EM','EMTrans').replace('DM','DeepMatch'))\n",
    "        \n",
    "        from scipy import stats\n",
    "        confidence_interval = 0.95\n",
    "        z_score = stats.norm.ppf((1 + confidence_interval) / 2)\n",
    "        margin_of_error = z_score * (np.sqrt(std_aud) / ((5)))\n",
    "\n",
    "        plt.fill_between(frac_float,\n",
    "                        mean_auc - margin_of_error,\n",
    "                        mean_auc + margin_of_error,\n",
    "                        alpha=0.25,color=style_dict[name.replace(task,'')]['color'])\n",
    "\n",
    "    \n",
    "# plt.legend(fontsize=50, loc = 'lower left',bbox_to_anchor = (-0.017,-0.017))\n",
    "# Formatter function for y-axis\n",
    "def format_y(value, tick_number): return f'{value:.3f}'\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(format_y))\n",
    "plt.tick_params(axis='both', which='major', length=10, width=2)\n",
    "plt.tick_params(axis='both', which='minor', length=5, width=1)\n",
    "if 'Fodor' in task:\n",
    "    plt.legend(fontsize=45, loc = 'lower left',bbox_to_anchor = (-0.017,-0.017))\n",
    "plt.grid()    \n",
    "# plt.ylim([0.95,1.005])\n",
    "tmp = plt.gca().get_xlim()\n",
    "top_axis = plt.twiny()\n",
    "top_axis.set_xlim(tmp)  # Match the limits of the bottom axis\n",
    "# top_axis.set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5])  \n",
    "top_axis.set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5,0.7,0.9])  \n",
    "\n",
    "\n",
    "# plt.twiny()\n",
    "if task == 'Fodors-Zagats':\n",
    "    plt.xticks([0, 0.1, .2, .3, .40, .50,0.7,0.9 ], ['27.0\\n±0.0', '27.8\\n±0.4', '27.7\\n±0.4', '27.1\\n±0.5', '26.3\\n±0.5', '25.3\\n±0.5','22.4\\n±0.5','18.5\\n±0.4'], fontsize=45)\n",
    "if task == 'Walmart-Amazon':\n",
    "    plt.xticks([0, 0.1, .2, .3, .40, .50, ], ['39.2\\n±0.0', '39.2\\n±0.5', '38.0\\n±0.8', '36.2\\n±0.7', '35.0\\n±0.7', '32.7\\n±1.01'], fontsize=45)\n",
    "if task == 'iTunes-Amazon':\n",
    "    plt.xticks([0, 0.1, .2, .3, .40, .50,0.7,0.9 ], ['32.8\\n±0.0', '33.9\\n±0.4', '33.8\\n±0.1', '32.5\\n±0.8', '29.8\\n±0.1', '28.5\\n±0.36','21.3\\n±0.7','17.9\\n±0.0'], fontsize=45)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Average Data Entropy \\n± variance\\n', fontsize=50)\n",
    "plt.tick_params(axis='both', which='major', length=10, width=2)\n",
    "plt.tight_layout()\n",
    "plt.ylim([0.94,1.0015])\n",
    "\n",
    "plt.savefig('iTunes-Amazon_hierarch_train.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_auc_ready(AUC):\n",
    "    from statistics import mean, stdev\n",
    "    data = AUC\n",
    "    AVG = []\n",
    "    STD = []\n",
    "    for sublist in data:\n",
    "        if len(sublist) > 1:  # Standard deviation requires at least 2 values\n",
    "            avg = mean(sublist)\n",
    "            std = stdev(sublist)**2\n",
    "        else:\n",
    "            avg = mean(sublist)\n",
    "            std = 0  # Std is undefined for a single element\n",
    "        STD.append(std)\n",
    "        AVG.append(avg)\n",
    "    return np.array(AVG),np.array(STD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company 112632 1 28200 25.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# task = \n",
    "# task = \n",
    "# task = \n",
    "\n",
    "# for task in ['WDC', 'company', 'abt_buy']:\n",
    "for task in ['company']:\n",
    "# for task in ['Fodors-Zagat','Walmart-Amazon','iTunes-Amazon']:\n",
    "# for task in ['Fodors-Zagat']:\n",
    "    # df1 = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/data/\" + task  +'/train.csv')\n",
    "    # df2 = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/data/\" + task  +'/valid.csv')\n",
    "    # df = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/data/\" + task  +'/test.csv')\n",
    "    df1 = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/DATA_/\" + task  +'/train.csv')\n",
    "    df2 = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/DATA_/\" + task  +'/valid.csv')\n",
    "    df3 = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/DATA_/\" + task  +'/test.csv')\n",
    "\n",
    "\n",
    "    df = pd.concat([df1, df2,df3], ignore_index=True)\n",
    "\n",
    "    # len(np.unique(list(df['left_Time']) + list(df['right_Time'])))\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        col = col.replace('left_','').replace('right_','')\n",
    "        if col not in cols:\n",
    "            if col not in ['id','label']:\n",
    "                cols.append(col)\n",
    "\n",
    "\n",
    "    # print(task, len(df) , len(df) * len(cols),len(cols))\n",
    "    print(task, len(df) ,len(cols),np.sum(df['label'] ==1), round(100*np.sum(df['label'] ==1)/len(df),0))\n",
    "\n",
    "    df_original  = df.copy()\n",
    "\n",
    "    df1 = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/DATA_/\" + task  +'/noisy_train.csv')\n",
    "    df2 = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/DATA_/\" + task  +'/noisy_valid.csv')\n",
    "    df3 = pd.read_csv(\"/Users/mohammad/Desktop/EM_Heterogeneity/DATA_/\" + task  +'/noisy_test.csv')\n",
    "\n",
    "\n",
    "    df = pd.concat([df1, df2,df3], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for WDC we have 442805 candids among 3998101 worss --> at each cell 1.55 words on average\n",
    "\n",
    "for abt_buy we have 257075 candid among  616299 words. --> at each cell 4.47 words on average\n",
    "\n",
    "for company we have 84.6M candid among 257.9M words. --> at each cell 375.6 words on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375.55879767739185"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "res = {}\n",
    "X = 0\n",
    "for col_ in cols:\n",
    "    if task =='abt_buy' and col_ == 'price': continue\n",
    "    for prep in ['left_','right_']:\n",
    "        col = prep + col_\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            \n",
    "            \n",
    "            str1 = df[col][i]\n",
    "            str2 = df_original[col][i]\n",
    "            if str(df[col][i]) == 'nan': str1 = 'nan'\n",
    "            if str(df_original[col][i]) == 'nan': str2 = 'nan'  \n",
    "            str1 = str1.replace('\\xa0',' ').replace('light-emitting diode','light-emitting-diode').replace('\"Digital Theater System\"','\"Digital-Theater-System\"')\n",
    "            str2 = str2.replace('\\xa0',' ').replace('light-emitting diode','light-emitting-diode').replace('\"Digital Theater System\"','\"Digital-Theater-System\"')\n",
    "            noisy = str1.split(' ')\n",
    "            orig = str2.split(' ')\n",
    "            phase = 0\n",
    "            for idx,row in enumerate(orig):\n",
    "                X+=1\n",
    "                try:\n",
    "                    if row != noisy[idx + phase]:\n",
    "                        FLAG = True\n",
    "                        offsets = range(-8, 9)  # Range of offsets to check (-8 to 8)\n",
    "                        for offset in offsets:\n",
    "                            if offset == 0:  # Skip checking the current index\n",
    "                                continue\n",
    "                            try:\n",
    "                                if row == noisy[idx + offset + phase]:\n",
    "                                    phase += offset\n",
    "                                    FLAG = False\n",
    "\n",
    "                                    break  # No need to check further offsets\n",
    "                            except IndexError:\n",
    "                                # Skip if offset goes out of bounds\n",
    "                                continue\n",
    "                        if FLAG:\n",
    "                            try:\n",
    "                                res[row]['cnt'] +=1\n",
    "                            except:\n",
    "                                res[row] = {'name': noisy[idx+phase], 'cnt' :1}\n",
    "                        \n",
    "                except IndexError:\n",
    "                    # Handle the case where idx + phase is out of bounds\n",
    "                    pass\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "def save_dict_to_json(data, filename):\n",
    "    \"\"\"Save a dictionary to a JSON file.\"\"\"\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)  # Use indent for readability\n",
    "\n",
    "save_dict_to_json(res, 'tmp.json')\n",
    "\n",
    "x=0\n",
    "for k in list(res.keys()):\n",
    "    x+= res[k]['cnt']\n",
    "\n",
    "x / (len(df)*2*len(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84599.877, 257923.611)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x/1000,X/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced Words: {}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"  # Lightweight transformer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_token_embeddings(tokens):\n",
    "    \"\"\"Generate embeddings for tokens using a pre-trained transformer.\"\"\"\n",
    "    encoded = tokenizer(tokens, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded)\n",
    "    # Use mean pooling of the last hidden state\n",
    "    return outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "def find_replacements(str1, str2, threshold=0.7):\n",
    "    \"\"\"Find replaced words between two strings using contextual embeddings.\"\"\"\n",
    "    # Tokenize the input strings\n",
    "    tokens1 = str1.split()\n",
    "    tokens2 = str2.split()\n",
    "\n",
    "    replacements = {}\n",
    "    embeddings1 = get_token_embeddings(tokens1)\n",
    "    embeddings2 = get_token_embeddings(tokens2)\n",
    "\n",
    "    # Compute pairwise similarity between tokens\n",
    "    for i, token1 in enumerate(tokens1):\n",
    "        for j, token2 in enumerate(tokens2):\n",
    "            similarity = cosine_similarity(\n",
    "                embeddings1[i].unsqueeze(0).numpy(), embeddings2[j].unsqueeze(0).numpy()\n",
    "            )[0][0]\n",
    "            if similarity > threshold and token1.lower() != token2.lower():\n",
    "                replacements[token1] = token2\n",
    "\n",
    "    return replacements\n",
    "\n",
    "# Test strings\n",
    "str1 = 'RAM Bracket 9\\\\\" Mount for 1.5\\\\\" Sphere'\n",
    "str2 = 'RAM Mount 9\\\\\" Arm for 1.5\\\\\" Ball'\n",
    "\n",
    "print(\"Replaced Words:\", replacements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RAM Bracket 9\\\\\" Mount for 1.5\\\\\" Sphere'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' RAM Mount 9\\\\\" Arm for 1.5\\\\\" Ball'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def find_parents(hierarchy, target, parents=None):\n",
    "    if parents is None:\n",
    "        parents = []\n",
    "\n",
    "    for key, value in hierarchy.items():\n",
    "        if key == target:  # If the target itself is a key\n",
    "            return parents + [key]\n",
    "        if isinstance(value, dict):  # If value is a nested dictionary\n",
    "            result = find_parents(value, target, parents + [key])\n",
    "            if result != -1:\n",
    "                return result\n",
    "        elif isinstance(value, list) and target in value:  # If value is a list containing the target\n",
    "            return parents + [key]\n",
    "\n",
    "    return -1  # Return -1 if the target is not found\n",
    "\n",
    "def get_leaves(nested_dict):\n",
    "    leaves = []\n",
    "    for key, value in nested_dict.items():\n",
    "        if isinstance(value, list):  # If the value is a list, add its elements\n",
    "            leaves.extend(value)\n",
    "        elif isinstance(value, dict):  # If the value is another dictionary, recurse\n",
    "            leaves.extend(get_leaves(value))\n",
    "    return leaves\n",
    "\n",
    "tmp = category_hierarchy\n",
    "stats = get_leaves(tmp)\n",
    "x = 0\n",
    "MAX = -1\n",
    "for row in stats:\n",
    "    x+=len(find_parents(tmp, row))\n",
    "    if len(find_parents(tmp, row)) > MAX:\n",
    "        MAX = len(find_parents(tmp, row))\n",
    "MAX, x/len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.5 + 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
